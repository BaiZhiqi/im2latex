{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# im2latex(S): Deep Learning Model\n",
    "\n",
    "&copy; Copyright 2017 Sumeet S Singh\n",
    "\n",
    "    This file is part of the im2latex solution (by Sumeet S Singh in particular since there are other solutions out there).\n",
    "\n",
    "    This program is free software: you can redistribute it and/or modify\n",
    "    it under the terms of the Affero GNU General Public License as published by\n",
    "    the Free Software Foundation, either version 3 of the License, or\n",
    "    (at your option) any later version.\n",
    "\n",
    "    This program is distributed in the hope that it will be useful,\n",
    "    but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "    Affero GNU General Public License for more details.\n",
    "\n",
    "    You should have received a copy of the Affero GNU General Public License\n",
    "    along with this program.  If not, see <http://www.gnu.org/licenses/>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "* Follows the [Show, Attend and Tell paper](https://www.semanticscholar.org/paper/Show-Attend-and-Tell-Neural-Image-Caption-Generati-Xu-Ba/146f6f6ed688c905fb6e346ad02332efd5464616)\n",
    "* [VGG ConvNet (16 or 19)](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) without the top-3 layers\n",
    "    * Pre-initialized with the VGG weights but allowed to train\n",
    "    * The ConvNet outputs $D$ dimensional vectors in a WxH grid where W and H are 1/16th of the input image size (due to 4 max-pool layers). Defining $W.H \\equiv L$ the ConvNet output represents L locations of the image $i \\in [1,L]$ and correspondingly outputs to L annotation vectors $a_i$, each of size $D$.\n",
    "* A dense (FC) attention model: The deterministic soft-attention model of the paper computes $\\alpha_{t,i}$ which is used to select or blend the $a_i$ vectors before being fed as inputs to the decoder LSTM network (see below).\n",
    "    * Inputs to the attention model are $a_i$ and $h_{t-1}$ (previous hidden state of LSTM network - see below)\n",
    "    and $$\\alpha_{t,i} = softmax ( f_{att}(a_i, h_{t-1}) )$$\n",
    "* A Decoder model: A conditioned LSTM that outputs probabilities of the text tokens $y_t$ at each step. The LSTM is conditioned upon $z_t = \\sum_i^L(\\alpha_{t,i}.a_i)$ and takes the previous hidden state $h_{t-1}$ as input. In addition, an embedding of the previous output $Ey_{t-1}$ is also input to the LSTM. At training time, $y_{t-1}$ would be derived from the training samples, while at inferencing time it would be fed-back from the previous predicted word.\n",
    "    * $y$ is taken from a fixed vocabulary of K words. An embedding matrix $E$ is used to narrow its representation. The embedding weights $E$ are learnt end-to-end by the model as well.\n",
    "    * The decoder LSTM uses a deep layer between $h_t$ and $y_t$. It is called a deep output layer and is described in [section 3.2.2 of this paper](https://www.semanticscholar.org/paper/How-to-Construct-Deep-Recurrent-Neural-Networks-Pascanu-G%C3%BCl%C3%A7ehre/533ee188324b833e059cb59b654e6160776d5812). That is:\n",
    "    $$ p(y_t) = Softmax \\Big( f_out(Ey_{t-1}, h_t, \\hat{z}_t) \\Big) $$\n",
    "* Initialization MLPs: Two MLPs are used to produce the initial memory-state of the LSTM as well as $h_{t-1}$ value. Each MLP takes in the entire image's features (i.e. average of $a_i$) as its input and is trained end-to-end.\n",
    "    $$ c_o = f_{init,c}\\Big( \\sum_i^L a_i \\Big) $$\n",
    "    $$ h_o = f_{init,h}\\Big( \\sum_i^L a_i \\Big) $$\n",
    "* Training:\n",
    "    * 3 models from above - all except the conv-net - are trained end-to-end using SGD\n",
    "    * The model is trained for a variable number of time steps - depending on each batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "1. Show, Attend and Tell\n",
    "    * [Paper](https://www.semanticscholar.org/paper/Show-Attend-and-Tell-Neural-Image-Caption-Generati-Xu-Ba/146f6f6ed688c905fb6e346ad02332efd5464616)\n",
    "    * [Slides](https://pdfs.semanticscholar.org/b336/f6215c3c15802ca5327cd7cc1747bd83588c.pdf?_ga=2.52116077.559595598.1498604153-2037060338.1496182671)\n",
    "    * [Author's Theano code](https://github.com/kelvinxu/arctic-captions)\n",
    "1. [Simonyan, Karen and Andrew Zisserman. “Very Deep Convolutional Networks for Large-Scale Image Recognition.” CoRR abs/1409.1556 (2014): n. pag.](http://www.robots.ox.ac.uk/~vgg/research/very_deep/)\n",
    "1. [im2latex solution of Harvard NLP](http://lstm.seas.harvard.edu/latex/)\n",
    "1. [im2latex-dataset tools forked from Harvard NLP](https://github.com/untrix/im2latex-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import dl_commons as dlc\n",
    "import tensorflow as tf\n",
    "from dl_commons import PD, mandatory, boolean, integer, decimal, equalto\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Input, Embedding, Dense, Activation, Dropout, Concatenate, Permute\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "import keras\n",
    "import threading\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_folder = '../data/generated2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab_size(data_dir_):\n",
    "    df_vocab = pd.read_pickle(os.path.join(data_folder, 'df_vocab.pkl'))\n",
    "    return df_vocab.id.max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'init_layers': 1, 'init_c_activation': 'tanh', 'MeanSumAlphaEquals1': True, 'att_weighted_gather': True, 'init_1_n': 512, 'init_1_activation': 'tanh', 'keep_prob': 1.0, 'init_dropout_rate': 0.2, 'att_layers': 1, 'init_h_activation': 'tanh', 'init_1_dropout_rate': 0.0, 'embeddings_initializer': 'glorot_uniform', 'image_shape': (120, 1075, 3), 'decoder_out_layers': 1, 'att_share_weights': True, 'att_1_n': 512, 'att_weights_initializer': 'glorot_normal', 'init_c_dropout_rate': 0.2, 'B': 128, 'D': 512, 'H': 3, 'K': 556, 'L': 99, 'pLambda': 0.0001, 'init_h_dropout_rate': 0.2, 'sum_logloss': True, 'output_follow_paper': True, 'W': 33, 'att_activation': 'tanh', 'm': 64, 'n': 1000, 'decoder_lstm_peephole': False, 'output_activation': 'tanh', 'output_1_n': 64}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del HYPER\n",
    "except:\n",
    "    pass\n",
    "\n",
    "HYPER_PD = (\n",
    "        PD('image_shape',\n",
    "           'Shape of input images. Should be a python sequence.',\n",
    "           None,\n",
    "           (120,1075,3)\n",
    "           ),\n",
    "        PD('B',\n",
    "           '(integer or None): Size of mini-batch for training, validation and testing.',\n",
    "           (None, 128),\n",
    "           128\n",
    "           ),\n",
    "        PD('K',\n",
    "           'Vocabulary size including zero',\n",
    "           xrange(500,1000),\n",
    "           556 #get_vocab_size(data_folder)\n",
    "           ),\n",
    "        PD('m',\n",
    "           '(integer): dimensionality of the embedded input vector (Ey / Ex)', \n",
    "           xrange(50,250),\n",
    "           64\n",
    "           ),\n",
    "        PD('H', 'Height of feature-map produced by conv-net. Specific to the dataset image size.', None, 3),\n",
    "        PD('W', 'Width of feature-map produced by conv-net. Specific to the dataset image size.', None, 33),\n",
    "        PD('L',\n",
    "           '(integer): number of pixels in an image feature-map = HxW (see paper or model description)', \n",
    "           integer(1),\n",
    "           lambda _, d: d['H'] * d['W']),\n",
    "        PD('D', \n",
    "           '(integer): number of features coming out of the conv-net. Depth/channels of the last conv-net layer.'\n",
    "           'See paper or model description.', \n",
    "           integer(1),\n",
    "           512),\n",
    "        PD('keep_prob', '(decimal): Value between 0.1 and 1.0 indicating the keep_probability of dropout layers.'\n",
    "           'A value of 1 implies no dropout.',\n",
    "           decimal(0.1, 1), \n",
    "           1.0),\n",
    "    ### Attention Model Params ###\n",
    "        PD('att_layers', 'Number of layers in the attention_a model', xrange(1,10), 1),\n",
    "        PD('att_1_n', 'Number of units in first layer of the attention model. Defaults to D as it is in the paper\"s source-code.', \n",
    "           xrange(1,10000),\n",
    "           equalto('D')),\n",
    "        PD('att_share_weights', 'Whether the attention model should share weights across the \"L\" image locations or not.'\n",
    "           'Choosing \"True\" conforms to the paper resulting in a (D+n,att_1_n) weight matrix. Choosing False will result in a MLP with (L*D+n,att_1_n) weight matrix. ',\n",
    "           boolean,\n",
    "           True),\n",
    "        PD('att_activation', \n",
    "           'Activation to use for the attention MLP model. Defaults to tanh as in the paper source.',\n",
    "           None,\n",
    "           'tanh'),\n",
    "        PD('att_weighted_gather', 'The paper\"s source uses an affine transform with trainable weights, to narrow the output of the attention'\n",
    "           \"model from (B,L,dim) to (B,L,1). I don't think this is helpful since there is no nonlinearity here.\" \n",
    "           \"Therefore I have an alternative implementation that simply averages the matrix (B,L,dim) to (B,L,1).\" \n",
    "           \"Default value however, is True in conformance with the paper's implementation.\",\n",
    "           (True, False),\n",
    "           True),\n",
    "        PD('att_weights_initializer', 'weights initializer to use for the attention model', None,\n",
    "           'glorot_normal'),\n",
    "    ### Embedding Layer ###\n",
    "        PD('embeddings_initializer', 'Initializer for embedding weights', None, 'glorot_uniform'),\n",
    "        #PD('embeddings_initializer_tf', 'Initializer for embedding weights', None, \n",
    "        #   tf.contrib.layers.xavier_initializer),\n",
    "    ### Decoder LSTM Params ###\n",
    "        PD('n',\n",
    "           '(integer): Number of hidden-units of the LSTM cell',\n",
    "           integer(100,10000),\n",
    "           1000),\n",
    "        PD('decoder_lstm_peephole',\n",
    "           '(boolean): whether to employ peephole connections in the decoder LSTM',\n",
    "           (True, False),\n",
    "           False),\n",
    "        PD('decoder_out_layers',\n",
    "           'Number of layers in the decoder output MLP. defaults to 1 as in the papers source',\n",
    "           xrange(1,10), 1),\n",
    "        PD('output_activation', 'Activtion function for deep output layer', None,\n",
    "           'tanh'),\n",
    "        PD('output_follow_paper',\n",
    "           'Output deep layer uses some funky logic in the paper instead of a straight MLP'\n",
    "           'Setting this value to True (default) will follow the paper\"s logic. Otherwise'\n",
    "           \"a straight MLP will be used.\", boolean, \n",
    "           True),\n",
    "        PD('output_1_n', \n",
    "           'Number of units in the first hidden layer of the output MLP. Used only if output_follow_paper == False'\n",
    "           \"Default's to 'm' - same as when output_follow_paper == True\", None,\n",
    "           equalto('m')),\n",
    "    ### Initializer MLP ###\n",
    "        PD('init_layers', 'Number of layers in the initializer MLP', xrange(1,10),\n",
    "           1),\n",
    "        PD('init_dropout_rate', '(decimal): Global dropout_rate variable for init_layer',\n",
    "           decimal(0.0, 0.9), \n",
    "           0.2),\n",
    "        PD('init_h_activation', '', None, 'tanh'),\n",
    "        PD('init_h_dropout_rate', '', \n",
    "           decimal(0.0, 0.9), \n",
    "           equalto('init_dropout_rate')),\n",
    "        PD('init_c_activation', '', None, 'tanh'),\n",
    "        PD('init_c_dropout_rate', '', \n",
    "           decimal(0.0, 0.9),\n",
    "           equalto('init_dropout_rate')),\n",
    "        PD('init_1_n', 'Number of units in hidden layer 1. The paper sets it to D',\n",
    "           integer(1, 10000), \n",
    "           equalto('D')),\n",
    "        PD('init_1_dropout_rate', '(decimal): dropout rate for the layer', \n",
    "           decimal(0.0, 0.9), \n",
    "           0.),\n",
    "        PD('init_1_activation', \n",
    "           'Activation function of the first layer. In the paper, the final' \n",
    "           'layer has tanh and all penultinate layers have relu activation', \n",
    "           None,\n",
    "           'tanh'),\n",
    "    ### Loss / Cost Layer ###\n",
    "        PD('sum_logloss',\n",
    "           'Whether to normalize log-loss per sample as in standard log perplexity ' \n",
    "           'calculation or whether to just sum up log-losses as in the paper. Defaults' \n",
    "           'to True in conformance with the paper.',\n",
    "           boolean,\n",
    "           True\n",
    "          ),\n",
    "        PD('MeanSumAlphaEquals1',\n",
    "          '(boolean): When calculating the alpha penalty, the paper uses the term: '\n",
    "           'square{1 - sum_over_t{alpha_t_i}}). This assumes that the mean sum_over_t should be 1. '\n",
    "           \"However, that's not true, since the mean of sum_over_t term should be C/L. This \"\n",
    "           \"variable if set to True, causes the term to change to square{C/L - sum_over_t{alpha_t_i}}). \"\n",
    "           \"The default value is True in conformance with the paper.\",\n",
    "          boolean,\n",
    "          False),\n",
    "        PD('pLambda', 'Lambda value for alpha penalty',\n",
    "           decimal(0),\n",
    "           0.0001)   \n",
    ")\n",
    "\n",
    "HYPER = dlc.HyperParams(HYPER_PD,\n",
    "        ## Overrides of default values.\n",
    "        ## FYI: By convention, all boolean params' default value is True\n",
    "        {\n",
    "            'att_weighted_gather': True,\n",
    "            'sum_logloss': True,\n",
    "            'MeanSumAlphaEquals1': True,\n",
    "            'output_follow_paper': True\n",
    "        })\n",
    "print HYPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Model\n",
    "[VGG ConvNet (16 or 19)](http://www.robots.ox.ac.uk/~vgg/research/very_deep/) without the top-3 layers\n",
    "* Pre-initialized with the VGG weights but allowed to train\n",
    "* The ConvNet outputs $D$ dimensional vectors in a WxH grid where W and H are scaled-down dimensions of the input image size (due to 5 max-pool layers). Defining $W.H \\equiv L$ the ConvNet output represents L locations of the image $i \\in [1,L]$ and correspondingly outputs to L annotation vectors $a_i$, each of size $D$.\n",
    "\n",
    "The conv-net is *not trained* in the original paper and therefore the files can be separately preprocessed and their outputs directly fed into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Input Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def make_batch_list(df_, batch_size_):\n",
    "    ## Make a list of batches\n",
    "    bin_lens = sorted(df_.bin_len.unique())\n",
    "    bin_counts = [df_[df_.bin_len==l].shape[0] for l in bin_lens]\n",
    "    batch_list = []\n",
    "    for i in range(len(bin_lens)):\n",
    "        bin_ = bin_lens[i]\n",
    "        num_batches = (bin_counts[i] // batch_size_)\n",
    "        ## Just making sure bin size is integral multiple of batch_size.\n",
    "        ## This is not a requirement for this function to operate, rather\n",
    "        ## is a way of possibly catching data-corrupting bugs\n",
    "        assert (bin_counts[i] % batch_size_) == 0\n",
    "        batch_list.extend([(bin_, j) for j in range(num_batches)])\n",
    "\n",
    "    np.random.shuffle(batch_list)\n",
    "    return batch_list\n",
    "\n",
    "class ShuffleIterator(object):\n",
    "    def __init__(self, df_, batch_size_):\n",
    "        self._df = df_.sample(frac=1)\n",
    "        self._batch_size = batch_size_\n",
    "        self._batch_list = make_batch_list(self._df, batch_size_)\n",
    "        self._next_pos = 0\n",
    "        self._num_items = (df_.shape[0] // batch_size_)\n",
    "        self.lock = threading.Lock()\n",
    "        \n",
    "#     def __iter__(self):\n",
    "#         return self\n",
    "    \n",
    "    def next(self):\n",
    "        ## This is an infinite iterator\n",
    "        with self.lock:\n",
    "            if self._next_pos >= self._num_items:\n",
    "                ## Recompose the batch-list\n",
    "                ## Shuffle the samples\n",
    "                self._df = self._df.sample(frac=1)\n",
    "                self._batch_list = make_batch_list(self._df, batch_size_)\n",
    "                self._next_pos %= self._num_items\n",
    "            next_pos = self._next_pos\n",
    "            self._next_pos += 1\n",
    "        \n",
    "        batch = self._batch_list[next_pos]\n",
    "        df_bin = self._df[self._df.bin_len == batch[0]]\n",
    "        assert df_bin.bin_len.iloc[batch[1]*self._batch_size] == batch[0]\n",
    "        assert df_bin.bin_len.iloc[(batch[1]+1)*self._batch_size-1] == batch[0]\n",
    "        return df_bin.iloc[batch[1]*self._batch_size : (batch[1]+1)*self._batch_size]\n",
    "\n",
    "class ImageIterator(ShuffleIterator):\n",
    "    def __init__(self, df_, batch_size_, image_dim_, image_dir_):\n",
    "        Shuffler.__init__(self, df_, batch_size_)\n",
    "        self._im_dim = image_dim_\n",
    "        self._image_dir = image_dir_\n",
    "\n",
    "    @staticmethod\n",
    "    def get_image_matrix(image_path_, height_, width_, padded_height_, padded_width_):\n",
    "        MAX_PIXEL = 255.0 # Ensure this is a float literal\n",
    "        ## Load image and convert to a 3-channel array\n",
    "        im_ar = ndimage.imread(os.path.join(image_dir_,sr_row_.image), mode='RGB')\n",
    "        ## normalize values to lie between -1.0 and 1.0.\n",
    "        ## This is done in place of data whitening - i.e. normalizing to mean=0 and std-dev=0.5\n",
    "        ## Is is a very rough technique but legit for images\n",
    "        im_ar = (im_ar - MAX_PIXEL/2.0) / MAX_PIXEL\n",
    "        height, width, channels = im_ar.shape\n",
    "        assert height == height\n",
    "        assert width == width\n",
    "        assert channels == 3\n",
    "        if (height < padded_height_) or (width < padded_width_):\n",
    "            ar = np.full((padded_height_, padded_width_), 0.5, dtype=np.float32)\n",
    "            h = (padded_height_-height)//2\n",
    "            ar[h:h+height, 0:width] = im_ar\n",
    "            im_ar = ar\n",
    "\n",
    "        return im_ar\n",
    "\n",
    "    def next(self):\n",
    "        df_batch = Shuffler.next(self)[['image', 'height', 'width']]\n",
    "        im_batch = []\n",
    "        for image in df_batch.image.itertuples():\n",
    "            im_batch.append(self._get_image_array(os.path.join(self._image_dir, image[0]), row[1], row[2], self._im_dim[0], self._im_dim[1]))\n",
    "            \n",
    "        return np.asarray(im_batch)\n",
    "\n",
    "class FormulaIterator(ShuffleIterator):\n",
    "    def __init__(self, df_, batch_size_, data_dir_, seq_filename_):\n",
    "        Shuffler.__init__(self, df_, batch_size_)\n",
    "        self._seq_data = pd.read_pickle(os.path.join(data_dir_, seq_filename_))\n",
    "        \n",
    "    def next(self):\n",
    "        df_batch = Shuffler.next(self)['bin_len']\n",
    "        bin_len = df_batch.iloc[0].bin_len\n",
    "        return self._seq_data[bin_len][df_batch.index].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder Model\n",
    "A dense (FC) attention model: The deterministic soft-attention model of the paper computes $\\alpha_{t,i}$ which is used to select or blend the $a_i$ vectors before being fed as inputs to the decoder LSTM network (see below).\n",
    "* Inputs to the attention model are $a_i$ and $h_{t-1}$ (previous hidden state of LSTM network - see below) and $$\\alpha_{t,i} = softmax ( f_{att}(a_i, h_{t-1}) )$$\n",
    "* Note that the model $f_{att}$ shares weights across all values of a_i (i.e. for all i = 1-L). Therefore the shared weight matrix for all a_i has shape (D, D), while shape of a is (B, L, D) where is B=batch-size. Weight matrix of h_i is separate and has the expected shape (n, D). This sharing of weights across a_i is interesting.\n",
    "\n",
    "A Decoder model: A conditioned LSTM that outputs probabilities of the text tokens $y_t$ at each step. The LSTM is conditioned upon $z_t = \\sum_i^L(\\alpha_{t,i}.a_i)$ and takes the previous hidden state $h_{t-1}$ as input. In addition, an embedding of the previous output $Ey_{t-1}$ is also input to the LSTM. At training time, $y_{t-1}$ would be derived from the training samples, while at inferencing time it would be fed-back from the previous predicted word.\n",
    "* $y$ is taken from a fixed vocabulary of K words. An embedding matrix $E$ is used to narrow its representation to an $m$ dimensional dense vector. The embedding weights $E$ are learnt end-to-end by the model as well.\n",
    "* The decoder LSTM uses a deep layer between $h_t$ and $y_t$. It is called a deep output layer and is described in [section 3.2.2 of this paper](https://www.semanticscholar.org/paper/How-to-Construct-Deep-Recurrent-Neural-Networks-Pascanu-G%C3%BCl%C3%A7ehre/533ee188324b833e059cb59b654e6160776d5812). That is:\n",
    "$$ p(y_t) = Softmax \\Big( f_out(Ey_{t-1}, h_t, \\hat{z}_t) \\Big) $$\n",
    "* Optionally $z_t = \\beta \\sum_i^L(\\alpha_{t,i}.a_i)$ where $\\beta = \\sigma(f_{\\beta}(h_{t-1}))$ is a scalar used to modulate the strength of the context. It turns out that for the original use-case of caption generation, the network would learn to emphasize objects by turning up the value of this scalar when it was focusing on objects. It is not clear at this time whether we'll need this feature for im2latex.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Im2LatexModel(object):\n",
    "    \"\"\"\n",
    "    One timestep of the decoder model. The entire function can be seen as a complex RNN-cell\n",
    "    that includes a LSTM stack and an attention model.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self._define_params()\n",
    "        self._numSteps = 0\n",
    "\n",
    "    def _define_attention_params(self):\n",
    "        \"\"\"Define Shared Weights for Attention Model\"\"\"\n",
    "        ## 1) Dense layer, 2) Optional gather layer and 3) softmax layer\n",
    "\n",
    "        ## Renaming HyperParams for convenience\n",
    "        B = HYPER.B\n",
    "        n = HYPER.n\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        m = HYPER.m\n",
    "        \n",
    "        ## _att_dense array indices start from 1\n",
    "        self._att_dense_layer = []\n",
    "\n",
    "        if HYPER.att_share_weights:\n",
    "        ## Here we'll effectively create L MLP stacks all sharing the same weights. Each\n",
    "        ## stack receives a concatenated vector of a(l) and h as input.\n",
    "            dim = D+n\n",
    "            for i in range(1, HYPER.att_layers+1):\n",
    "                n_units = HYPER['att_%d_n'%(i,)]; assert(n_units <= dim)\n",
    "                self._att_dense_layer.append(Dense(n_units, activation=HYPER.att_activation,\n",
    "                                                   batch_input_shape=(B,L,dim)))\n",
    "                dim = n_units\n",
    "            ## Optional gather layer (that comes after the Dense Layer)\n",
    "            if HYPER.att_weighted_gather:\n",
    "                self._att_gather_layer = Dense(1, activation='linear') # output shape = (B, L, 1)\n",
    "        else:\n",
    "            ## concatenate a and h_prev and pass them through a MLP. This is different than the theano\n",
    "            ## implementation of the paper because we flatten a from (B,L,D) to (B,L*D). Hence each element\n",
    "            ## of the L*D vector receives its own weight because the effective weight matrix here would be\n",
    "            ## shape (L*D, num_dense_units) as compared to (D, num_dense_units) as in the shared_weights case\n",
    "            dim = L*D+n        \n",
    "            for i in range(1, HYPER.att_layers+1):\n",
    "                n_units = HYPER['att_%d_n'%(i,)]; assert(n_units <= dim)\n",
    "                self._att_dense_layer.append(Dense(n_units, activation=HYPER.att_actv,\n",
    "                                                   batch_input_shape=(B,dim)))\n",
    "                dim = n_units\n",
    "        \n",
    "        assert dim >= L\n",
    "        self._att_softmax_layer = Dense(L, activation='softmax', name='alpha')\n",
    "        \n",
    "    def _build_attention_model(self, a, h_prev):\n",
    "        B = HYPER.B\n",
    "        n = HYPER.n\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        h = h_prev\n",
    "\n",
    "        assert K.int_shape(h_prev) == (B, n)\n",
    "        assert K.int_shape(a) == (B, L, D)\n",
    "\n",
    "        ## For #layers > 1 this will endup being different than the paper's implementation\n",
    "        if HYPER.att_share_weights:\n",
    "            \"\"\"\n",
    "            Here we'll effectively create L MLP stacks all sharing the same weights. Each\n",
    "            stack receives a concatenated vector of a(l) and h as input.\n",
    "\n",
    "            TODO: We could also\n",
    "            use 2D convolution here with a kernel of size (1,D) and stride=1 resulting in\n",
    "            an output dimension of (L,1,depth) or (B, L, 1, depth) including the batch dimension.\n",
    "            That may be more efficient.\n",
    "            \"\"\"\n",
    "            ## h.shape = (B,n). Convert it to (B,1,n) and then broadcast to (B,L,n) in order\n",
    "            ## to concatenate with feature vectors of 'a' whose shape=(B,L,D)\n",
    "            h = K.tile(K.expand_dims(h, axis=1), (1,L,1))\n",
    "            ## Concatenate a and h. Final shape = (B, L, D+n)\n",
    "            ah = tf.concat([a,h], -1)\n",
    "            for i in range(HYPER.att_layers) :\n",
    "                ah = self._att_dense_layer[i](ah)\n",
    "\n",
    "            ## Below is roughly how it is implemented in the code released by the authors of the paper\n",
    "#                 for i in range(1, HYPER.att_a_layers+1):\n",
    "#                     a = Dense(HYPER['att_a_%d_n'%(i,)], activation=HYPER.att_actv)(a)\n",
    "#                 for i in range(1, HYPER.att_h_layers+1):\n",
    "#                     h = Dense(HYPER['att_h_%d_n'%(i,)], activation=HYPER.att_actv)(h)    \n",
    "#                ah = a + K.expand_dims(h, axis=1)\n",
    "\n",
    "            ## Gather all activations across the features; go from (B, L, dim) to (B,L,1).\n",
    "            ## One could've just summed/averaged them all here, but the paper uses yet\n",
    "            ## another set of weights to accomplish this. So we'll keeep that as an option.\n",
    "            if HYPER.att_weighted_gather:\n",
    "                ah = self._att_gather_layer(ah) # output shape = (B, L, 1)\n",
    "                ah = K.squeeze(ah, axis=2) # output shape = (B, L)\n",
    "            else:\n",
    "                ah = K.mean(ah, axis=2) # output shape = (B, L)\n",
    "\n",
    "        else: # weights not shared across L\n",
    "            ## concatenate a and h_prev and pass them through a MLP. This is different than the theano\n",
    "            ## implementation of the paper because we flatten a from (B,L,D) to (B,L*D). Hence each element\n",
    "            ## of the L*D vector receives its own weight because the effective weight matrix here would be\n",
    "            ## shape (L*D, num_dense_units) as compared to (D, num_dense_units) as in the shared_weights case\n",
    "\n",
    "            ## Concatenate a and h. Final shape will be (B, L*D+n)\n",
    "            ah = K.concatenate(K.batch_flatten(a), h)\n",
    "            for i in range(HYPER.att_layers):\n",
    "                ah = self._att_dense_layer(ah)\n",
    "            ## At this point, ah.shape = (B, dim)\n",
    "\n",
    "        alpha = self._att_softmax_layer(ah) # output shape = (B, L)\n",
    "        assert K.int_shape(alpha) == (B, L)\n",
    "        return alpha\n",
    "            \n",
    "    def _define_output_params(self):\n",
    "        ## Renaming HyperParams for convenience\n",
    "        B = HYPER.B\n",
    "        n = HYPER.n\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        m = HYPER.m\n",
    "        Kv= HYPER.K\n",
    "\n",
    "        ## First layer of output MLP\n",
    "        ## Affine transformation of h_t and z_t from size n/D to m followed by a summation\n",
    "        self._output_affine = Dense(m, activation='linear', batch_input_shape=(B,n+D)) # output size = (B, m)\n",
    "        ## non-linearity for the first layer - will be chained by the _call function after adding Ex / Ey\n",
    "        self._output_activation = Activation(HYPER.output_activation)\n",
    "\n",
    "        ## Additional layers if any\n",
    "        if HYPER.decoder_out_layers > 1:\n",
    "            self._output_dense = []\n",
    "            for i in range(1, HYPER.decoder_out_layers):\n",
    "                self._output_dense.append(Dense(m, activation=HYPER['output_%d_activation'%i], \n",
    "                                           batch_input_shape=(B,m))\n",
    "                                         )\n",
    "\n",
    "        ## Final softmax layer\n",
    "        self._output_softmax = Dense(Kv, activation='softmax', batch_input_shape=(B,m))\n",
    "        \n",
    "    def _build_output_layer(self, Ex_t, h_t, z_t):\n",
    "        ## Renaming HyperParams for convenience\n",
    "        B = HYPER.B\n",
    "        n = HYPER.n\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        m = HYPER.m\n",
    "        Kv =HYPER.K\n",
    "        \n",
    "        assert K.int_shape(Ex_t) == (B, m)\n",
    "        assert K.int_shape(h_t) == (B, n)\n",
    "        assert K.int_shape(z_t) == (B, D)\n",
    "        \n",
    "        ## First layer of output MLP\n",
    "        ## Affine transformation of h_t and z_t from size n/D to size m followed by a summation\n",
    "        o_t = Dense(m, activation='linear', batch_input_shape=(B,n+D))(tf.concat([h_t, z_t], -1)) # output size = (B, m)\n",
    "        o_t = o_t + Ex_t\n",
    "        \n",
    "        ## non-linearity for the first layer\n",
    "        o_t = Activation(HYPER.output_activation)(o_t)\n",
    "\n",
    "        ## Subsequent MLP layers\n",
    "        if HYPER.decoder_out_layers > 1:\n",
    "            for i in range(1, HYPER.decoder_out_layers):\n",
    "                o_t = Dense(m, \n",
    "                            activation=HYPER['output_%d_activation'%i], \n",
    "                            batch_input_shape=(B,m))(o_t)\n",
    "                \n",
    "        ## Final logits\n",
    "        logits_t = Dense(Kv, activation=HYPER.output_activation, batch_input_shape=(B,m))(o_t) # shape = (B,K)\n",
    "        assert K.int_shape(logits_t) == (B, Kv)\n",
    "        \n",
    "        # softmax\n",
    "        return tf.nn.softmax(logits_t), logits_t\n",
    "\n",
    "    def _define_init_params(self):\n",
    "        ## As per the paper, this is a two-headed MLP. It has a stack of common layers at the bottom\n",
    "        ## two output layers at the top - one each for h and c LSTM states.\n",
    "        self._init_layer = []\n",
    "        self._init_dropout = []\n",
    "        for i in xrange(1, HYPER.init_layers):\n",
    "            key = 'init_%d_'%i\n",
    "            self._init_layer.append(Dense(HYPER[key+'n'], activation=Hyper[key+'activation']))\n",
    "            if HYPER[key+'dropout_rate'] > 0.0:\n",
    "                self._init_dropout.append(Dropout(HYPER[key+'dropout_rate']))\n",
    "\n",
    "        ## Final layer for h\n",
    "        self._init_h = Dense(HYPER['n'], activation=HYPER['init_h_activation'])\n",
    "        if HYPER['init_h_dropout_rate'] > 0.0:\n",
    "            self._init_h_dropout = Dropout(HYPER['init_h_dropout_rate'])\n",
    "\n",
    "        ## Final layer for c\n",
    "        self._init_c = Dense(HYPER['n'], activation=HYPER['init_c_activation'])\n",
    "        if HYPER['init_c_dropout_rate'] > 0.0:\n",
    "            self._init_c_dropout = Dropout(HYPER['init_c_dropout_rate'])\n",
    "\n",
    "    def _build_init_layer(self, a):\n",
    "        assert K.int_shape(a) == (HYPER.B, HYPER.L, HYPER.D)\n",
    "        \n",
    "        ################ Initializer MLP ################\n",
    "        with tf.variable_scope('Initializer_MLP'):\n",
    "\n",
    "            ## As per the paper, this is a two-headed MLP. It has a stack of common layers at the bottom,\n",
    "            ## two output layers at the top - one each for h and c LSTM states.\n",
    "            a = K.mean(a, axis=1) # final shape = (B, D)\n",
    "            for i in xrange(1, HYPER.init_layers):\n",
    "                key = 'init_%d_'%i\n",
    "                a = self._init_layer[i](a)\n",
    "                if HYPER[key+'dropout_rate'] > 0.0:\n",
    "                    a = self._init_dropout[i](a)\n",
    "\n",
    "            init_c = self._init_c(a)\n",
    "            if HYPER['init_c_dropout_rate'] > 0.0:\n",
    "                init_c = self._init_c_dropout(init_c)\n",
    "\n",
    "            init_h = self._init_h(a)\n",
    "            if HYPER['init_h_dropout_rate'] > 0.0:\n",
    "                init_h = self._init_h_dropout(init_h)\n",
    "\n",
    "            assert K.int_shape(init_c) == (HYPER.B, HYPER.n)\n",
    "            assert K.int_shape(init_h) == (HYPER.B, HYPER.n)\n",
    "\n",
    "        return init_c, init_h\n",
    "            \n",
    "    def _embedding_lookup2(self, ids):\n",
    "        B = HYPER.B\n",
    "        m = HYPER.m\n",
    "        assert self._embedding is not None\n",
    "        assert K.int_shape(ids) == (B,)\n",
    "        embedded = self._embedding(K.expand_dims(ids, axis=-1)) # (None,1,m)\n",
    "        embedded = tf.squeeze(embedded, axis=1) # (None,m)\n",
    "        embedded = tf.reshape(embedded, (B,m)) # (B,m)\n",
    "        return embedded\n",
    "    \n",
    "    def _embedding_lookup(self, ids):\n",
    "        B = HYPER.B\n",
    "        m = HYPER.m\n",
    "        assert self._embedding_matrix is not None\n",
    "        assert K.int_shape(ids) == (B,)\n",
    "        embedded = tf.nn.embedding_lookup(self._embedding_matrix, ids)\n",
    "        embedded = tf.reshape(embedded, (B,m)) # (B,m)\n",
    "        return embedded    \n",
    "    \n",
    "    def _define_params(self):\n",
    "        ## Renaming HyperParams for convenience\n",
    "        B = HYPER.B\n",
    "        n = HYPER.n\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        m = HYPER.m\n",
    "        Kv = HYPER.K\n",
    "        att_actv = HYPER.att_activation\n",
    "        e_init = HYPER.embeddings_initializer\n",
    "\n",
    "        ################ Attention Model ################\n",
    "        with tf.variable_scope('Attention'):\n",
    "            self._define_attention_params()\n",
    "                \n",
    "        ################ Embedding Layer ################\n",
    "        with tf.variable_scope('Ey'):\n",
    "            self._embedding = Embedding(Kv, m, \n",
    "                                        embeddings_initializer=e_init, \n",
    "                                        mask_zero=True, \n",
    "                                        input_length=1,\n",
    "                                        batch_input_shape=(B,1)\n",
    "                                        #input_shape=(1,)\n",
    "                                        ) ## (B, 1, m)\n",
    "            \n",
    "            ## Above Embedding layer will get replaced by this one.\n",
    "            self._embedding_matrix = tf.get_variable('Embedding_Matrix', (Kv, m))\n",
    "        \n",
    "        ################ Decoder LSTM Cell ################\n",
    "        with tf.variable_scope('Decoder_LSTM'):\n",
    "            #LSTM by Zaremba et. al 2014: http://arxiv.org/abs/1409.2329\n",
    "            self._decoder_lstm = tf.contrib.rnn.LSTMBlockCell(n, forget_bias=1.0, \n",
    "                                                              use_peephole=HYPER.decoder_lstm_peephole)\n",
    "            \n",
    "        ################ Output Layer ################\n",
    "        with tf.variable_scope('Decoder_Output_Layer'):\n",
    "            self._define_output_params()\n",
    "\n",
    "        ################ Initializer MLP ################\n",
    "        with tf.variable_scope('Initializer_MLP'):\n",
    "            self._define_init_params()\n",
    "            \n",
    "    def _build_rnn_step1(self, out_t_1, x_t, testing=False):\n",
    "        \"\"\"\n",
    "        Builds tf graph for the first iteration of the RNN. Works for both training and testing graphs.\n",
    "        \"\"\"\n",
    "        return self._build_rnn_step(out_t_1, x_t, isStep1=True, testing=testing)\n",
    "        \n",
    "    def _build_rnn_training_stepN(self, out_t_1, x_t):\n",
    "        \"\"\"\n",
    "        Builds tf graph for the subsequent iterations of the RNN - training mode.\n",
    "        \"\"\"\n",
    "        return self._build_rnn_step(out_t_1, x_t, isStep1=False, testing=False)\n",
    "        \n",
    "    def _build_rnn_testing_stepN(self, out_t_1, x_t):\n",
    "        \"\"\"\n",
    "        Builds tf graph for the subsequent iterations of the RNN - testing mode.\n",
    "        \"\"\"\n",
    "        return self._build_rnn_step(out_t_1, x_t, isStep1=False, testing=True)\n",
    "        \n",
    "    def _build_rnn_step(self, out_t_1, x_t, isStep1=False, testing=False):\n",
    "        \"\"\"\n",
    "        TODO: Incorporate Dropout\n",
    "        Builds/threads tf graph for one RNN iteration.\n",
    "        Conforms to loop function fn required by tf.scan. Takes in previous lstm states (h and c), \n",
    "        the current input and the image annotations (a) as input and outputs the states and outputs for the\n",
    "        current timestep.\n",
    "        Note that input(t) = Ey(t-1). Input(t=0) = Null. When training, the target output is used for Ey\n",
    "        whereas at prediction time (via. beam-search for e.g.) the actual output is used.\n",
    "        Args:\n",
    "            x_t (tensor): is a input for one time-step. Should be a tensor of shape (batch-size, 1).\n",
    "            out_t_1 (tuple of tensors): Output returned by this function at previous time-step.\n",
    "        Returns:\n",
    "            out_t (tuple of tensors): The output y_t shape= (B,K) - the probability of words/tokens. Also returns\n",
    "                states needed in the next iteration of the RNN - i.e. (h_t, lstm_states_t and a). lstm_states_t = \n",
    "                (h_t, c_t) - which means h_t is included twice in the returned tuple.            \n",
    "        \"\"\"\n",
    "        #x_t = input at t             # shape = (B,)\n",
    "        step = out_t_1[0] + 1\n",
    "        h_t_1 = out_t_1[1]            # shape = (B,n)\n",
    "        lstm_states_t_1 = out_t_1[2]  # shape = ((B,n), (B,n)) = (c_t_1, h_t_1)\n",
    "        a = out_t_1[3]                # shape = (B, L, D)\n",
    "        if not isStep1: ## init_accum does not have everything\n",
    "            yProbs_t_1 = out_t_1[4]           # shape = (B, Kv)\n",
    "        #yLogits_t_1 = out_t_1[5]          # shape = (B, Kv)\n",
    "        #alpha_t_1 = out_t_1[6]\n",
    "        \n",
    "        B = HYPER.B\n",
    "        m = HYPER.m\n",
    "        n = HYPER.n\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        Kv = HYPER.K\n",
    "        \n",
    "        assert K.int_shape(h_t_1) == (B, n)\n",
    "        assert K.int_shape(a) == (B, L, D)\n",
    "        assert K.int_shape(lstm_states_t_1[1]) == (B, n)\n",
    "        \n",
    "        if not isStep1:\n",
    "            assert K.int_shape(yProbs_t_1) == (B, Kv)\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            if testing:\n",
    "                x_t = tf.argmax(yProbs_t_1, axis=1)\n",
    "        elif testing:\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "        \n",
    "        ################ Attention Model ################\n",
    "        with tf.variable_scope('Attention'):\n",
    "            alpha_t = self._build_attention_model(a, h_t_1) # alpha.shape = (B, L)\n",
    "\n",
    "        ################ Soft deterministic attention: z = alpha-weighted mean of a ################\n",
    "        ## (B, L) batch_dot (B,L,D) -> (B, D)\n",
    "        with tf.variable_scope('Phi'):\n",
    "            z_t = K.batch_dot(alpha_t, a, axes=[1,1]) # z_t.shape = (B, D)\n",
    "\n",
    "        ################ Embedding layer ################\n",
    "        with tf.variable_scope('Ey'):\n",
    "            Ex_t = self._embedding(K.expand_dims(x_t, axis=-1) ) # output.shape= (None,1,m)\n",
    "            Ex_t = K.squeeze(Ex_t, axis=1) # output.shape= (None,m)\n",
    "            Ex_t = K.reshape(Ex_t, (B,m)) # (B,m)\n",
    "            \n",
    "        ################ Decoder Layer ################\n",
    "        with tf.variable_scope(\"Decoder_LSTM\") as var_scope:\n",
    "            (h_t, lstm_states_t) = self._decoder_lstm(K.concatenate((Ex_t, z_t)), lstm_states_t_1) # h_t.shape=(B,n)\n",
    "            \n",
    "        ################ Decoder Layer ################\n",
    "        with tf.variable_scope('Output_Layer'):\n",
    "            yProbs_t, yLogits_t = self._build_output_layer(Ex_t, h_t, z_t) # yProbs_t.shape = (B,K)\n",
    "        \n",
    "        assert K.int_shape(h_t) == (B, n)\n",
    "        assert K.int_shape(a) == (B, L, D)\n",
    "        assert K.int_shape(lstm_states_t[1]) == (B, n)\n",
    "        assert K.int_shape(yProbs_t) == (B, Kv)\n",
    "        assert K.int_shape(yLogits_t) == (B, Kv)\n",
    "        assert K.int_shape(alpha_t) == (B, L)\n",
    "        \n",
    "        return step, h_t, lstm_states_t, a, yProbs_t, yLogits_t, alpha_t\n",
    "        \n",
    "    def _build_rnn_testing(self, a, y_s, init_c, init_h):\n",
    "        return self._build_rnn(a, y_s, init_c, init_h, False)\n",
    "\n",
    "    def _build_rnn_training(self, a, y_s, init_c, init_h):\n",
    "        return self._build_rnn(a, y_s, init_c, init_h, True)\n",
    "\n",
    "    def _build_rnn(self, a, y_s, init_c, init_h, training=True):\n",
    "        B = HYPER.B\n",
    "        L = HYPER.L\n",
    "        D = HYPER.D\n",
    "        n = HYPER.n\n",
    "        assert K.int_shape(a) == (B, L, D)\n",
    "        assert K.int_shape(y_s) == (B, None) # (B, T, 1)\n",
    "        assert K.int_shape(init_c) == (B, n)\n",
    "        assert K.int_shape(init_h) == (B, n)\n",
    "        \n",
    "        # LSTMStateTuple Stores two elements: (c, h), in that order.\n",
    "        init_lstm_states = tf.contrib.rnn.LSTMStateTuple(init_c, init_h)\n",
    "\n",
    "        ## tf.scan requires time-dimension to be the first dimension\n",
    "        \n",
    "        y_s = K.permute_dimensions(y_s, (1, 0)) # (T, B)\n",
    "\n",
    "        ################ Build x_s ################\n",
    "        ## First step of x_s is zero indicating begin-of-sequence\n",
    "        x_s = tf.zeros((1, tf.shape(y_s)[1]), dtype=tf.int32)\n",
    "        if training:\n",
    "            ## x_s is y_s shifted forward by 1 timestep\n",
    "            ## last time-step of y_s which is zero indicating <eos> will get removed.\n",
    "            x_s = K.concatenate((x_s, y_s[0:-2]), axis=0)\n",
    "            \n",
    "\n",
    "        ################ Build RNN ################\n",
    "        with tf.variable_scope('RNN'):\n",
    "            initial_accum = (0, init_h, init_lstm_states, a)\n",
    "            ## Weights are created in first step and then reused in subsequent steps.\n",
    "            ## Hence we need to separate them out.\n",
    "            step1_out = self._build_rnn_step1(initial_accum, x_s[0], testing=(not training))\n",
    "            ## Subsequent steps in training are different than validation/testing/prediction\n",
    "            ## Hence we need to separate them\n",
    "            if training:\n",
    "                stepN_out = tf.scan(self._build_rnn_training_stepN, x_s[1:], initializer=step1_out)\n",
    "            else:\n",
    "                ## Uses y_t_1 as input instead of x_t\n",
    "                stepN_out = tf.scan(self._build_rnn_testing_stepN, x_s[1:], initializer=step1_out)\n",
    "\n",
    "            yProbs1, yLogits1, alpha1 = step1_out[4], step1_out[5], step1_out[6]\n",
    "            yProbsN, yLogitsN, alphaN = stepN_out[4], stepN_out[5], stepN_out[6]\n",
    "\n",
    "            yProbs = K.concatenate([K.expand_dims(yProbs1, axis=0), yProbsN], axis=0)\n",
    "            yLogits = K.concatenate([K.expand_dims(yLogits1, axis=0), yLogitsN], axis=0)\n",
    "            alpha = K.concatenate([K.expand_dims(alpha1, axis=0), alphaN], axis=0)\n",
    "        \n",
    "            ## Switch the batch dimension back to first position - (B, T, ...)\n",
    "            yProbs = K.permute_dimensions(yProbs, [1,0,2])\n",
    "            yLogits = K.permute_dimensions(yLogits, [1,0,2])\n",
    "            alpha = K.permute_dimensions(alpha, [1,0,2])\n",
    "            \n",
    "        return yProbs, yLogits, alpha\n",
    "        \n",
    "    def _build_loss(self, yLogits, y_s, alpha, sequence_lengths):\n",
    "        assert K.int_shape(yLogits) == (HYPER.B, None, HYPER.K) # (B, T, K)\n",
    "        assert K.int_shape(y_s) == (HYPER.B, None) # (B, T)\n",
    "        assert K.int_shape(alpha) == (HYPER.B, None, HYPER.L) # (B, T, L)\n",
    "        assert K.int_shape(sequence_lengths) == (HYPER.B,) # (B,)\n",
    "        \n",
    "        ################ Build Cost Function ################\n",
    "        with tf.variable_scope('Cost'):\n",
    "            sequence_mask = tf.sequence_mask(sequence_lengths, maxlen=tf.shape(y_s)[1], dtype=tf.float32) # (B, T)\n",
    "\n",
    "            ## Masked negative log-likelihood of the sequence.\n",
    "            ## Note that log(product(p_t)) = sum(log(p_t)) therefore taking taking log of\n",
    "            ## joint-sequence-probability is same as taking sum of log of probability at each time-step\n",
    "\n",
    "            ## Compute Sequence Log-Loss / Log-Likelihood = -Log( product(p_t) ) = -sum(Log(p_t))\n",
    "            if HYPER.sum_logloss:\n",
    "                ## Here we do not normalize the log-loss across time-steps because the\n",
    "                ## paper as well as it's source-code do not do that.\n",
    "                loss_vector = tf.contrib.seq2seq.sequence_loss(logits=yLogits, \n",
    "                                                               targets=y_s, \n",
    "                                                               weights=sequence_mask, \n",
    "                                                               average_across_timesteps=False,\n",
    "                                                               average_across_batch=True)\n",
    "                loss = tf.reduce_sum(loss_vector) # scalar\n",
    "            else: ## Standard log perplexity (average per-word)\n",
    "                loss = tf.contrib.seq2seq.sequence_loss(logits=yLogits, \n",
    "                                                               targets=y_s, \n",
    "                                                               weights=sequence_mask, \n",
    "                                                               average_across_timesteps=True,\n",
    "                                                               average_across_batch=True)\n",
    "\n",
    "            ## Calculate the alpha penalty: lambda * sum_over_i(square(C/L - sum_over_t(alpha_i)))\n",
    "            ## \n",
    "            if HYPER.MeanSumAlphaEquals1:\n",
    "                mean_sum_alpha_i = 1.0\n",
    "            else:\n",
    "                mean_sum_alpha_i = tf.cast(sequence_lengths, dtype=tf.float32) / HYPER.L # (B,)\n",
    "\n",
    "            sum_alpha_i = tf.reduce_sum(tf.multiply(alpha,sequence_mask), axis=1, keep_dims=False)# (B, L)\n",
    "            squared_diff = tf.squared_difference(sum_alpha_i, mean_sum_alpha_i)\n",
    "            penalty = HYPER.pLambda * tf.reduce_sum(squared_diff, keep_dims=False) # scalar\n",
    "            \n",
    "            cost = loss + penalty\n",
    "            \n",
    "            ################ Build Scoring Function ################\n",
    "            ## People have used BLEU score, but that probably is not suitable for markup comparison\n",
    "            ## Best of course is to compare images produced by the output markup.\n",
    "            \n",
    "            ## Compute CTC score with intermediate blanks collapsed (we've collapsed all blanks in our\n",
    "            ## train/test sequences to a single space so we'll hopefully get a better comparison by\n",
    "            ## using CTC.)\n",
    "        \n",
    "        return cost\n",
    "    \n",
    "    def _build_image_context(self, image_batch):\n",
    "        ## Conv-net\n",
    "        assert K.int_shape(image_batch) == (HYPER.B,) + HYPER.image_shape\n",
    "        ################ Build VGG Net ################\n",
    "        with tf.variable_scope('VGGNet'):\n",
    "            # K.set_image_data_format('channels_last')\n",
    "            convnet = VGG16(include_top=False, weights='imagenet', pooling=None, input_shape=HYPER.image_shape)\n",
    "            convnet.trainable = False\n",
    "            print 'convnet output_shape = ', convnet.output_shape\n",
    "            a = convnet(image_batch)\n",
    "            assert K.int_shape(a) == (HYPER.B, HYPER.H, HYPER.W, HYPER.D)\n",
    "\n",
    "            ## Combine HxW into a single dimension L\n",
    "            a = tf.reshape(a, shape=(HYPER.B or -1, HYPER.L, HYPER.D))\n",
    "            assert K.int_shape(a) == (HYPER.B, HYPER.L, HYPER.D)\n",
    "        \n",
    "        return a\n",
    "        \n",
    "    def build(self):\n",
    "        B = HYPER.B\n",
    "        Kv = HYPER.K\n",
    "        L = HYPER.L\n",
    "        \n",
    "        ## TODO: Introduce Beam Search\n",
    "        ## TODO: Introduce Stochastic Learning\n",
    "        \n",
    "        rv = dlc.Properties()\n",
    "        im = tf.placeholder(dtype=tf.float32, shape=(HYPER.B,) + HYPER.image_shape, name='image_batch')\n",
    "        y_s = tf.placeholder(tf.int32, shape=(HYPER.B, None))\n",
    "        #a = tf.placeholder(tf.float32, shape=(HYPER.B, HYPER.L, HYPER.D))\n",
    "        Ts = tf.placeholder(tf.int32, shape=(HYPER.B,))\n",
    "\n",
    "        a = self._build_image_context(im)\n",
    "        init_c, init_h = self._build_init_layer(a)\n",
    "        yProbs, yLogits, alpha = self._build_rnn_training(a, y_s, init_c, init_h)\n",
    "        self._build_rnn_testing(a, y_s, init_c, init_h)\n",
    "        loss = self._build_loss(yLogits, y_s, alpha, Ts)\n",
    "        \n",
    "        assert K.int_shape(yProbs) == (B, None, Kv)\n",
    "        assert K.int_shape(yLogits) == (B, None, Kv)\n",
    "        assert K.int_shape(alpha) == (B, None, L)\n",
    "        \n",
    "        rv.im = im\n",
    "        rv.y_s = y_s\n",
    "        rv.Ts = Ts\n",
    "        rv.yProbs = yProbs\n",
    "        rv.yLogits = yLogits\n",
    "        rv.alpha = alpha\n",
    "        \n",
    "        return rv.freeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# with tf.variable_scope('test_1'):\n",
    "#     m = Im2LatexModel().build()\n",
    "#     print 'yProbs shape = ', K.int_shape(m.yProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Im2LatexRNNStateTuple = collections.namedtuple(\"Im2LatexRNNStateTuple\", ('lstm_state', 'alpha'))\n",
    "\n",
    "class Im2LatexDecoderRNN(tf.nn.rnn_cell.RNNCell):\n",
    "    \"\"\"\n",
    "    One timestep of the decoder model. The entire function can be seen as a complex RNN-cell\n",
    "    that includes a LSTM stack and an attention model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, context, reuse=None):\n",
    "        super(Im2LatexDecoderRNN, self).__init__(_reuse=reuse)\n",
    "        self.C = config.copy().freeze()\n",
    "        self._a = context ## Image features from the Conv-Net\n",
    "\n",
    "        #LSTM by Zaremba et. al 2014: http://arxiv.org/abs/1409.2329\n",
    "        self._LSTM_cell = tf.contrib.rnn.LSTMBlockCell\n",
    "\n",
    "        assert K.int_shape(self._a) == (config.B, config.L, config.D)\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        n = self.C.n\n",
    "        Kv = self.C.K\n",
    "        L = self.C.L\n",
    "    \n",
    "        # lstm_states_t, alpha_t\n",
    "        #return Im2LatexRNNStateTuple(tf.nn.rnn_cell.LSTMStateTuple(n, n), L)\n",
    "        return ((n,n), L)\n",
    "\n",
    "    def zero_state(self, batch_size, dtype):\n",
    "        with ops.name_scope(type(self).__name__ + \"ZeroState\", values=[batch_size]):\n",
    "            return (self._LSTM_cell.zero_state(batch_size, dtype), tf.zeros(dtype, shape=(batch_size, self.C.L)))\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        # yLogits\n",
    "        return self.C.K\n",
    "       \n",
    "    def _attention_model(self, a, h_prev):\n",
    "        CONF = self.C\n",
    "        B = CONF.B\n",
    "        n = CONF.n\n",
    "        L = CONF.L\n",
    "        D = CONF.D\n",
    "        h = h_prev\n",
    "\n",
    "        assert K.int_shape(h_prev) == (B, n)\n",
    "        assert K.int_shape(a) == (B, L, D)\n",
    "\n",
    "        ## For #layers > 1 this will endup being different than the paper's implementation\n",
    "        if CONF.att_share_weights:\n",
    "            \"\"\"\n",
    "            Here we'll effectively create L MLP stacks all sharing the same weights. Each\n",
    "            stack receives a concatenated vector of a(l) and h as input.\n",
    "\n",
    "            TODO: We could also\n",
    "            use 2D convolution here with a kernel of size (1,D) and stride=1 resulting in\n",
    "            an output dimension of (L,1,depth) or (B, L, 1, depth) including the batch dimension.\n",
    "            That may be more efficient.\n",
    "            \"\"\"\n",
    "            ## h.shape = (B,n). Convert it to (B,1,n) and then broadcast to (B,L,n) in order\n",
    "            ## to concatenate with feature vectors of 'a' whose shape=(B,L,D)\n",
    "            h = K.tile(K.expand_dims(h, axis=1), (1,L,1))\n",
    "            ## Concatenate a and h. Final shape = (B, L, D+n)\n",
    "            ah = tf.concat([a,h], -1); dim = D+n\n",
    "            for i in range(1, CONF.att_layers+1):\n",
    "                n_units = CONF['att_%d_n'%(i,)]; assert(n_units <= dim)\n",
    "                ah = Dense(n_units, activation=CONF.att_activation, batch_input_shape=(B,L,dim))(ah)\n",
    "                dim = n_units\n",
    "                \n",
    "            ## Below is roughly how it is implemented in the code released by the authors of the paper\n",
    "#                 for i in range(1, CONF.att_a_layers+1):\n",
    "#                     a = Dense(CONF['att_a_%d_n'%(i,)], activation=CONF.att_actv)(a)\n",
    "#                 for i in range(1, CONF.att_h_layers+1):\n",
    "#                     h = Dense(CONF['att_h_%d_n'%(i,)], activation=CONF.att_actv)(h)    \n",
    "#                ah = a + K.expand_dims(h, axis=1)\n",
    "\n",
    "            ## Gather all activations across the features; go from (B, L, dim) to (B,L,1).\n",
    "            ## One could've just summed/averaged them all here, but the paper uses yet\n",
    "            ## another set of weights to accomplish this. So we'll keeep that as an option.\n",
    "            if CONF.att_weighted_gather:\n",
    "                ah = Dense(1, activation='linear')(ah) # output shape = (B, L, 1)\n",
    "                ah = K.squeeze(ah, axis=2) # output shape = (B, L)\n",
    "            else:\n",
    "                ah = K.mean(ah, axis=2) # output shape = (B, L)\n",
    "                \n",
    "            alpha = tf.nn.softmax(ah) # output shape = (B, L)\n",
    "            \n",
    "        else: # weights not shared across L\n",
    "            ## concatenate a and h_prev and pass them through a MLP. This is different than the theano\n",
    "            ## implementation of the paper because we flatten a from (B,L,D) to (B,L*D). Hence each element\n",
    "            ## of the L*D vector receives its own weight because the effective weight matrix here would be\n",
    "            ## shape (L*D, num_dense_units) as compared to (D, num_dense_units) as in the shared_weights case\n",
    "\n",
    "            ## Concatenate a and h. Final shape will be (B, L*D+n)\n",
    "            ah = K.concatenate(K.batch_flatten(a), h)\n",
    "            dim = L*D+n\n",
    "            for i in range(1, CONF.att_layers+1):\n",
    "                n_units = CONF['att_%d_n'%(i,)]; assert(n_units <= dim)\n",
    "                ah = Dense(n_units, activation=CONF.att_actv, batch_input_shape=(B,dim))(ah)\n",
    "                dim = n_units\n",
    "            ## At this point, ah.shape = (B, dim)        \n",
    "            assert dim >= L        \n",
    "            ## NOTE: An extra dense layer is not needed if dim == L. Simply a softmax activation would\n",
    "            ## suffice in that case.\n",
    "            alpha = self.Dense(L, activation='softmax', name='alpha')(ah) # output shape = (B, L)\n",
    "        \n",
    "        assert K.int_shape(alpha) == (B, L)\n",
    "        return alpha\n",
    "\n",
    "    def _build_decoder_lstm(self, Ex_t, z_t, lstm_states_t_1):\n",
    "        \"\"\"Represents invocation of the decoder lstm. (h_t, lstm_states_t) = *(z_t|Ex_t, lstm_states_t_1)\"\"\"\n",
    "        CONF = self.C\n",
    "        m = self.C.m\n",
    "        D = self.C.D\n",
    "        B = self.C.B\n",
    "        n = self.C.n\n",
    "        \n",
    "        inputs_t = K.concatenate((Ex_t, z_t))\n",
    "        assert K.int_shape(inputs_t) == (B, m+D)\n",
    "        assert K.int_shape(lstm_states_t_1[1]) == (B, n)\n",
    "        \n",
    "        ## TODO: Make this multi-layered\n",
    "        (h_t, lstm_states_t) = self._LSTM_cell(n, forget_bias=1.0,\n",
    "                                            use_peephole=CONF.decoder_lstm_peephole)(inputs_t, lstm_states_t_1)\n",
    "        return (h_t, lstm_states_t)\n",
    "\n",
    "    def _build_output_layer(self, Ex_t, h_t, z_t):\n",
    "        \n",
    "        ## Renaming HyperParams for convenience\n",
    "        CONF = self.C\n",
    "        B = self.C.B\n",
    "        n = self.C.n\n",
    "        L = self.C.L\n",
    "        D = self.C.D\n",
    "        m = self.C.m\n",
    "        Kv =self.C.K\n",
    "        \n",
    "        assert K.int_shape(Ex_t) == (B, m)\n",
    "        assert K.int_shape(h_t) == (B, n)\n",
    "        assert K.int_shape(z_t) == (B, D)\n",
    "        \n",
    "        ## First layer of output MLP\n",
    "        if not CONF.output_follow_paper: ## Follow the paper.\n",
    "            ## Affine transformation of h_t and z_t from size n/D to bring it down to m\n",
    "            o_t = Dense(m, activation='linear', batch_input_shape=(B,n+D))(tf.concat([h_t, z_t], -1)) # o_t: (B, m)\n",
    "            ## h_t and z_t are both dimension m now. So they can now be added to Ex_t.\n",
    "            o_t = o_t + Ex_t # Paper does not multiply this with weights - weird.\n",
    "            ## non-linearity for the first layer\n",
    "            o_t = Activation(CONF.output_activation)(o_t)\n",
    "            dim = m\n",
    "        else: ## Use a straight FC layer\n",
    "            o_t = K.concatenate((Ex_t, h_t, z_t)) # (B, m+n+D)\n",
    "            o_t = Dense(CONF.output_1_n, activation=CONF.output_activation, batch_input_shape=(B,D+m+n))(o_t)\n",
    "            dim = CONF.output_1_n\n",
    "            \n",
    "        ## Subsequent MLP layers\n",
    "        if CONF.decoder_out_layers > 1:\n",
    "            for i in range(2, CONF.decoder_out_layers+1):\n",
    "                o_t = Dense(m, activation=CONF.output_activation, \n",
    "                            batch_input_shape=(B,dim))(o_t)\n",
    "                \n",
    "        ## Final logits layer\n",
    "        logits_t = Dense(Kv, activation=CONF.output_activation, batch_input_shape=(B,m))(o_t) # shape = (B,K)\n",
    "        assert K.int_shape(logits_t) == (B, Kv)\n",
    "        \n",
    "        # return tf.nn.softmax(logits_t), logits_t\n",
    "        return logits_t\n",
    "\n",
    "    def call(self, inputs, state):\n",
    "        \"\"\"\n",
    "        TODO: Incorporate Dropout\n",
    "        Builds/threads tf graph for one RNN iteration.\n",
    "        Takes in previous lstm states (h and c),\n",
    "        the current input and the image annotations (a) as input and outputs the states and outputs for the\n",
    "        current timestep.\n",
    "        Note that input(t) = Ey(t-1). Input(t=0) = Null. When training, the target output is used for Ey\n",
    "        whereas at prediction time (via. beam-search for e.g.) the actual output is used.\n",
    "        \"\"\"\n",
    "\n",
    "        Ex_t = inputs                          # shape = (B,m)\n",
    "        state = Im2LatexRNNStateTuple(state[0], state[1])\n",
    "        lstm_states_t_1 = state.lstm_state   # shape = ((B,n), (B,n)) = (c_t_1, h_t_1)\n",
    "        alpha_t_1 = state.alpha            # shape = (B, L)\n",
    "        h_t_1 = lstm_states_t_1[1]\n",
    "        a = self._a\n",
    "\n",
    "        CONF = self.C\n",
    "        B = CONF.B\n",
    "        m = CONF.m\n",
    "        n = CONF.n\n",
    "        L = CONF.L\n",
    "        D = CONF.D\n",
    "        Kv =CONF.K\n",
    "\n",
    "        print 'shape(Ex_t) = ', K.int_shape(Ex_t)\n",
    "        assert K.int_shape(Ex_t) == (B,m)\n",
    "        assert K.int_shape(h_t_1) == (B, n)\n",
    "        assert K.int_shape(lstm_states_t_1[1]) == (B, n)\n",
    "        assert K.int_shape(alpha_t_1) == (B, L)\n",
    "\n",
    "        ################ Attention Model ################\n",
    "        with tf.variable_scope('Attention'):\n",
    "            alpha_t = self._attention_model(a, h_t_1) # alpha.shape = (B, L)\n",
    "\n",
    "        ################ Soft deterministic attention: z = alpha-weighted mean of a ################\n",
    "        ## (B, L) batch_dot (B,L,D) -> (B, D)\n",
    "        with tf.variable_scope('Phi'):\n",
    "            z_t = K.batch_dot(alpha_t, a, axes=[1,1]) # z_t.shape = (B, D)\n",
    "\n",
    "        ################ Decoder Layer ################\n",
    "        with tf.variable_scope(\"Decoder_LSTM\") as var_scope:\n",
    "            (h_t, lstm_states_t) = self._build_decoder_lstm(Ex_t, z_t, lstm_states_t_1) # h_t.shape=(B,n)\n",
    "\n",
    "        ################ Decoder Layer ################\n",
    "        with tf.variable_scope('Output_Layer'):\n",
    "            yLogits_t = self._build_output_layer(Ex_t, h_t, z_t) # yProbs_t.shape = (B,K)\n",
    "\n",
    "        assert K.int_shape(h_t) == (B, n)\n",
    "        assert K.int_shape(lstm_states_t.h) == (B, n)\n",
    "        assert K.int_shape(lstm_states_t.c) == (B, n)\n",
    "        #assert K.int_shape(yProbs_t) == (B, Kv)\n",
    "        assert K.int_shape(yLogits_t) == (B, Kv)\n",
    "        assert K.int_shape(alpha_t) == (B, L)\n",
    "\n",
    "        return yLogits_t, (tuple(lstm_states_t), alpha_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_s[:,0] shape:  (128,)\n",
      "embedding_lookup shape:  (128, 64)\n",
      "convnet output_shape =  (None, 3, 33, 512)\n",
      "rnn  ((1000, 1000), 99) 556\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected behavior when reshaping between beam width and batch size.  The reshaped tensor has shape: (128, 10, 100).  We expected it to have shape (batch_size, beam_width, depth) == (128, 10, 1000).  Perhaps you forgot to create a zero_state with batch_size=encoder_batch_size * beam_width?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-448142ee686f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_run18'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mtest_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-448142ee686f>\u001b[0m in \u001b[0;36mtest_rnn\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                    \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                    \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                    beam_width=10)\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'decoder._start_tokens: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m'decoder._start_inputs: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sumeet/anaconda/envs/im2latex/lib/python2.7/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, embedding, start_tokens, end_token, initial_state, beam_width, output_layer, length_penalty_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m     self._initial_cell_state = nest.map_structure(\n\u001b[1;32m    192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_split_batch_beams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         initial_state, self._cell.state_size)\n\u001b[0m\u001b[1;32m    194\u001b[0m     self._start_tokens = array_ops.tile(\n\u001b[1;32m    195\u001b[0m         array_ops.expand_dims(self._start_tokens, 1), [1, self._beam_width])\n",
      "\u001b[0;32m/Users/sumeet/anaconda/envs/im2latex/lib/python2.7/site-packages/tensorflow/python/util/nest.pyc\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **check_types_dict)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 325\u001b[0;31m       structure[0], [func(*x) for x in entries])\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sumeet/anaconda/envs/im2latex/lib/python2.7/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.pyc\u001b[0m in \u001b[0;36m_maybe_split_batch_beams\u001b[0;34m(self, t, s)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0m_check_maybe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_split_batch_beams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sumeet/anaconda/envs/im2latex/lib/python2.7/site-packages/tensorflow/contrib/seq2seq/python/ops/beam_search_decoder.pyc\u001b[0m in \u001b[0;36m_split_batch_beams\u001b[0;34m(self, t, s)\u001b[0m\n\u001b[1;32m    348\u001b[0m                        \u001b[0;34m\"forgot to create a zero_state with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                        \u001b[0;34m\"batch_size=encoder_batch_size * beam_width?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                        % (reshaped_t.shape, expected_reshaped_shape))\n\u001b[0m\u001b[1;32m    351\u001b[0m     \u001b[0mreshaped_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_reshaped_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreshaped_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected behavior when reshaping between beam width and batch size.  The reshaped tensor has shape: (128, 10, 100).  We expected it to have shape (batch_size, beam_width, depth) == (128, 10, 1000).  Perhaps you forgot to create a zero_state with batch_size=encoder_batch_size * beam_width?"
     ]
    }
   ],
   "source": [
    "def test_rnn():\n",
    "    B = HYPER.B\n",
    "    Kv = HYPER.K\n",
    "    L = HYPER.L\n",
    "\n",
    "    ## TODO: Introduce Beam Search\n",
    "    ## TODO: Introduce Stochastic Learning\n",
    "\n",
    "    m = Im2LatexModel()\n",
    "    rv = dlc.Properties()\n",
    "    im = tf.placeholder(dtype=tf.float32, shape=(HYPER.B,) + HYPER.image_shape, name='image_batch')\n",
    "    y_s = tf.placeholder(tf.int32, shape=(HYPER.B, None))\n",
    "    print 'y_s[:,0] shape: ', K.int_shape(y_s[:,0])\n",
    "    print 'embedding_lookup shape: ', K.int_shape(m._embedding_lookup(y_s[:,0]))\n",
    "    a = m._build_image_context(im)\n",
    "    rnn = Im2LatexDecoderRNN(HYPER, a)\n",
    "    print 'rnn ', rnn.state_size, rnn.output_size\n",
    "    #init_c, init_h = m._build_init_layer(a)\n",
    "    init_c = tf.placeholder(tf.float32, shape=(HYPER.B, HYPER.n))\n",
    "    init_h = tf.placeholder(tf.float32, shape=(HYPER.B, HYPER.n))\n",
    "    init_alpha = tf.placeholder(tf.float32, shape=(HYPER.B, HYPER.L))\n",
    "    \n",
    "    decoder = tf.contrib.seq2seq.BeamSearchDecoder(rnn, \n",
    "                                                   m._embedding_lookup,\n",
    "                                                   y_s[:,0],\n",
    "                                                   0,\n",
    "                                                   ((init_c, init_h), init_alpha),\n",
    "                                                   beam_width=10)\n",
    "    print 'decoder._start_tokens: ', K.int_shape(decoder._start_tokens)\n",
    "    print 'decoder._start_inputs: ', K.int_shape(decoder._start_inputs)\n",
    "    final_outputs, final_state, final_sequence_lengths = tf.contrib.seq2seq.dynamic_decode(decoder,\n",
    "                                                                                           #maximum_iterations=10,\n",
    "                                                                                           swap_memory=True)\n",
    "    print 'final_outputs: ', K.int_shape(final_outputs.predicted_ids)\n",
    "    print 'final_state: ', (final_state)\n",
    "    print 'final_sequence_lengths', (final_sequence_lengths)\n",
    "\n",
    "with tf.variable_scope('test_run18', reuse=False):\n",
    "    test_rnn()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Conv-net\n",
    "# # K.set_image_data_format('channels_last')\n",
    "# #image_input = Input(shape=HYPER.image_shape, name='image_input')\n",
    "# image_input = tf.placeholder(dtype=tf.float32, shape=(HYPER.B,) + HYPER.image_shape, name='image_batch2')\n",
    "# convnet = VGG16(include_top=False, weights='imagenet', pooling=None, input_shape=HYPER.image_shape)\n",
    "# convnet.trainable = False\n",
    "# print 'convnet output_shape = ', convnet.output_shape\n",
    "# a = convnet(image_input)\n",
    "# a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
