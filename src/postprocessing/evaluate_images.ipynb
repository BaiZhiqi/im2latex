{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.extend(['../commons'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "from IPython.display import display, Math, Latex\n",
    "from IPython.display import Image as ipImage\n",
    "from six.moves import cPickle as pickle\n",
    "import string\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 50\n",
    "pd.options.display.max_colwidth = 600\n",
    "pd.options.display.expand_frame_repr = False\n",
    "pd.options.display.colheader_justify = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import data_commons as dtc\n",
    "import dl_commons as dlc\n",
    "import viz_commons as viz\n",
    "from viz_commons import VisualizeDir, DiffParams, VisualizeStep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/home/sumeet/anaconda2/lib/python27.zip',\n",
       " '/home/sumeet/anaconda2/lib/python2.7',\n",
       " '/home/sumeet/anaconda2/lib/python2.7/plat-linux2',\n",
       " '/home/sumeet/anaconda2/lib/python2.7/lib-tk',\n",
       " '/home/sumeet/anaconda2/lib/python2.7/lib-old',\n",
       " '/home/sumeet/anaconda2/lib/python2.7/lib-dynload',\n",
       " '/home/sumeet/anaconda2/lib/python2.7/site-packages',\n",
       " '/home/sumeet/anaconda2/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/home/sumeet/.ipython',\n",
       " '../commons']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Arguments\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# storedir = '/zpool_3TB/i2l/tb_metrics/2017-12-21 02-20-10 PST 140K_score_89.0/test_runs/step_00168100_score89.0_publish/store_2'\n",
    "storedir = '/zpool_3TB/i2l/tb_metrics/2017-12-25 21-04-15 PST 140K_noRegroup_score89.09/test_runs/step_00167526_score89.0_publish/store_2'\n",
    "clobber = False\n",
    "dump = False\n",
    "\n",
    "original_image_dir = '/zpool_3TB/i2l/data/dataset5/formula_images'\n",
    "rel_dumpdir = 'eval_images'\n",
    "dumpdir = os.path.join(storedir, rel_dumpdir)\n",
    "rendered_dir = os.path.join(storedir, rel_dumpdir, 'rendered_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /zpool_3TB/i2l/tb_metrics/2017-12-25 21-04-15 PST 140K_noRegroup_score89.09/test_runs/step_00167526_score89.0_publish/store_2/hyper.pkl and /zpool_3TB/i2l/tb_metrics/2017-12-25 21-04-15 PST 140K_noRegroup_score89.09/test_runs/step_00167526_score89.0_publish/store_2/args.pkl\n",
      "Loaded ../data/dataset5/training_56/df_train.pkl (114408, 3)\n"
     ]
    }
   ],
   "source": [
    "vd = VisualizeDir(os.path.expanduser(storedir))\n",
    "last_step = vd.view_steps()[1][-1]\n",
    "print('last_step = %d' % last_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vs = VisualizeStep(vd, 'test', last_step)\n",
    "df, df_result, df_data, sr_label = vs.get_preds(rel_dumpdir=rel_dumpdir, dump=dump, clobber=clobber)\n",
    "# df = vs.dump_preds(rel_dumpdir=rel_dumpdir, dump=dump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sr_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Images\n",
    "Render images using render_latex.py (https://github.com/untrix/im2latex/blob/master/thirdparty/harvardnlp_im2markup/scripts/evaluation/render_latex.py) which is derived from harvardnlp code base (https://github.com/harvardnlp/im2markup). See their github page for details on how to run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for image in df.image_name:\n",
    "#     os.symlink(os.path.join(original_image_dir, image), os.path.join(golden_image_dir, image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate images\n",
    "Evaluate image match using evaluate_image.py (https://github.com/untrix/im2latex/blob/master/thirdparty/harvardnlp_im2markup/scripts/evaluation/evaluate_image.py) also from harvard nlp code base. See their github page for details on how to run the script. However, make sure to use the code from this repository because it has been modified to produce an unmatched_files.txt output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
