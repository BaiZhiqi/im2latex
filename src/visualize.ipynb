{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import codecs\n",
    "from IPython.display import display\n",
    "from six.moves import cPickle as pickle\n",
    "import string\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "width = None\n",
    "pd.options.display.max_rows = 600\n",
    "pd.options.display.max_columns = width\n",
    "pd.options.display.max_colwidth = 600\n",
    "pd.options.display.width = width\n",
    "pd.options.display.max_seq_items = None\n",
    "pd.options.display.expand_frame_repr = False\n",
    "pd.options.display.colheader_justify = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import data_commons as dtc\n",
    "import dl_commons as dlc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VisualizeDir(object):\n",
    "    def __init__(self, storedir, gen_datadir='../data/generated2'):\n",
    "        self._storedir = storedir\n",
    "        self._logdir = os.path.join(storedir, '..')\n",
    "        try:\n",
    "            self._hyper = dtc.load(self._logdir, 'hyper.pkl')\n",
    "            self._args = dtc.load(self._logdir, 'args.pkl')\n",
    "        except:\n",
    "            self._hyper = dtc.load(self._storedir, 'hyper.pkl')\n",
    "            self._args = dtc.load(self._storedir, 'args.pkl')\n",
    "\n",
    "        self._word2id = pd.read_pickle(os.path.join(gen_datadir, 'dict_vocab.pkl'))\n",
    "        i2w = pd.read_pickle(os.path.join(gen_datadir, 'dict_id2word.pkl'))\n",
    "        for i in range(-1,-11,-1):\n",
    "            i2w[i] = '%d'%i\n",
    "        self._id2word = {}\n",
    "        ## Append space after all commands beginning with a backslash (except backslash alone)\n",
    "        for i, w in i2w.items():\n",
    "            if w[0] == '\\\\':\n",
    "              self._id2word[i] = w + \" \"  \n",
    "            else:\n",
    "                self._id2word[i] = w \n",
    "        self._id2word[self._word2id['id']['\\\\']] = '\\\\'\n",
    "    \n",
    "    @property\n",
    "    def storedir(self):\n",
    "        return self._storedir\n",
    "    \n",
    "    @property\n",
    "    def w2i(self):\n",
    "        return self._word2id['id']\n",
    "\n",
    "    @property\n",
    "    def i2w(self):\n",
    "        return self._id2word\n",
    "    \n",
    "    @property\n",
    "    def max_steps(self):\n",
    "        steps = [int(os.path.basename(f).split('_')[-1].split('.')[0]) for f in os.listdir(self._storedir)]\n",
    "        epoch_steps = [int(os.path.basename(f).split('_')[-1].split('.')[0]) for f in os.listdir(self._storedir) if f.startswith('validation')]\n",
    "        return sorted(steps)[-1], sorted(epoch_steps)[-1]\n",
    "        \n",
    "    @property\n",
    "    def args(self):\n",
    "        return self._args\n",
    "    \n",
    "    @property\n",
    "    def hyper(self):\n",
    "        return self._hyper\n",
    "    \n",
    "    def keys(self, graph, step):\n",
    "        with h5py.File(os.path.join(self._storedir, '%s_%d.h5'%(graph,step))) as h5:\n",
    "            return h5.keys()\n",
    "\n",
    "    def np(self, graph, step, key):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            graph: 'training' or 'validation'\n",
    "            step:  step who's output is to be fetched\n",
    "            key:   key of object to fetch - e.g. 'predicted_ids'\n",
    "        \"\"\"\n",
    "        with h5py.File(os.path.join(self._storedir, '%s_%d.h5'%(graph,step))) as h5:\n",
    "            return h5[key][...]\n",
    "    \n",
    "    def df(self, graph, step, key):\n",
    "        return pd.DataFrame(self.np(graph, step, key))\n",
    "    \n",
    "    def words(self, graph, step, key, key2=None):\n",
    "        df = self.df(graph, step, key)\n",
    "        df2 = self.df(graph, step, key2) if (key2 is not None) else None\n",
    "        \n",
    "        if key2 is None:\n",
    "            return df.applymap(lambda x: self._id2word[x])\n",
    "        else:\n",
    "            return pd.DataFrame({'%s'%key: df.applymap(lambda x: self._id2word[x]), '%s'%key2: df2.applymap(lambda x: self._id2word[x])})\n",
    "\n",
    "    def strs(self, graph, step, key, key2=None, mingle=True):\n",
    "        df_str = self.words(graph, step, key)\n",
    "        df_str2 = self.words(graph, step, key2) if (key2 is not None) else None\n",
    "        \n",
    "        ## each token's string version - excepting backslash - has a space appended to it,\n",
    "        ## therefore the string output should be compile if the prediction was syntactically correct\n",
    "        if key2 == None:\n",
    "            return pd.DataFrame([\"\".join(row) for row in df_str.itertuples(index=False)])\n",
    "        else:\n",
    "            if mingle:\n",
    "                ar1 = [\"\".join(row) for row in df_str.itertuples(index=False)]\n",
    "                ar2 = [\"\".join(row) for row in df_str2.itertuples(index=False)]\n",
    "                data = {'%s_%d %s / %s\\t\\t(%s)'%(graph, step, key, key2, self._storedir): [e for t in zip(ar1, ar2) for e in t]}\n",
    "            else:\n",
    "                data = {'%s_%d.%s\\t\\t(%s)'%(graph, step, key, self._storedir): [\"\".join(row) for row in df_str.itertuples(index=False)], '%s_%d.%s\\t\\t(%s)'%(graph, step, key2, self._storedir): [\"\".join(row) for row in df_str2.itertuples(index=False)]}\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "#             df.style.set_caption('%s/%s_%s'%(self._storedir, graph, step))\n",
    "            return df\n",
    "        \n",
    "    def prune_logs(self, save_epochs=1, dry_run=True):\n",
    "        \"\"\"Save the latest save_epochs logs and remove the rest.\"\"\"\n",
    "        def get_step(f):\n",
    "            return int(os.path.basename(f).split('_')[-1].split('.')[0])\n",
    "        \n",
    "        epoch_steps = [get_step(f) for f in os.listdir(self._storedir) if f.startswith('validation')]\n",
    "        epoch_steps = list(set(epoch_steps))\n",
    "        print 'epoch_steps: %s'%epoch_steps\n",
    "        if len(epoch_steps) <= save_epochs:\n",
    "            print('Only %d full epochs were found. Deleting nothing.'%epoch_steps)\n",
    "            return False\n",
    "        else:\n",
    "            epoch_steps.sort(reverse=True)\n",
    "            max_step = epoch_steps[save_epochs]\n",
    "            training_files = [f for f in os.listdir(self._storedir) if f.startswith('training')]\n",
    "            training_steps = set([get_step(f) for f in training_files])\n",
    "            steps_to_remove = set(filter(lambda s: (s<max_step) and (s not in epoch_steps), training_steps))\n",
    "            files_to_remove = set([f for f in training_files if (get_step(f) in steps_to_remove)])\n",
    "            files_to_keep = set([f for f in os.listdir(self._storedir)]) - files_to_remove\n",
    "            if dry_run:\n",
    "                print '%d files will be kept\\n'%len(files_to_keep), pd.Series(sorted(list(files_to_keep), key=get_step))\n",
    "                print '%d files will be removed\\n'%len(files_to_remove), pd.Series(sorted(list(files_to_remove), key=get_step))\n",
    "            else:\n",
    "                for f in files_to_remove:\n",
    "                    os.remove(os.path.join(self._storedir, f))\n",
    "                print 'Removed %d files\\n'%len(files_to_remove), pd.Series(sorted(list(files_to_remove), key=get_step))\n",
    "\n",
    "    def prune_snapshots(self, keep=10, dry_run=True):\n",
    "        \"\"\" Keep the latest 'save' snapshots. Delete the rest. \"\"\"\n",
    "        def get_step(f):\n",
    "            return int(os.path.basename(f).split('.')[0].split('snapshot-')[1])\n",
    "        \n",
    "        files = [f for f in os.listdir(self._logdir) if f.startswith('snapshot-')]\n",
    "        steps = list(set([get_step(f) for f in files]))\n",
    "        if len(steps) <= keep:\n",
    "            print 'Nothing to delete'\n",
    "            return\n",
    "        else:\n",
    "            steps.sort(reverse=True)\n",
    "            steps_to_keep = set(steps[:keep])\n",
    "            steps_to_remove = set(steps) - steps_to_keep\n",
    "            print 'steps to keep: ', sorted(list(steps_to_keep))\n",
    "            print 'steps to remove: ', sorted(list(steps_to_remove))\n",
    "            files_to_remove = [f for f in files if (get_step(f) not in steps_to_keep) ]\n",
    "            files_to_remove = sorted(files_to_remove, key=get_step)\n",
    "            \n",
    "            if dry_run:\n",
    "                print '%d files will be removed\\n'%len(files_to_remove), pd.Series(files_to_remove)\n",
    "            else:\n",
    "                for f in files_to_remove:\n",
    "                    os.remove(os.path.join(self._logdir, f))\n",
    "                print '%d files removed\\n'%len(files_to_remove), pd.Series(files_to_remove)\n",
    "        \n",
    "class VisualizeStep():\n",
    "    def __init__(self, visualizer, step):\n",
    "        self._step = step\n",
    "        self._visualizer = visualizer\n",
    "        \n",
    "    def keys(self, graph):\n",
    "        return self._visualizer.keys(graph, self._step)\n",
    "    \n",
    "    def np(self, graph, key):\n",
    "        return self._visualizer.np(graph, self._step, key)\n",
    "    \n",
    "    def df(self, graph, step, key):\n",
    "        return pd.DataFrame.df(self.np(graph, step, key))\n",
    "    \n",
    "    def words(self, graph, key, key2=None):\n",
    "        return self._visualizer.words(graph, self._step, key, key2)\n",
    "\n",
    "    def strs(self, graph, key, key2=None, mingle=True):\n",
    "        return self._visualizer.strs(graph, self._step, key, key2, mingle)\n",
    "\n",
    "class DiffParams(object):\n",
    "    def __init__(self, dir1, dir2):\n",
    "        self._dir1 = dir1\n",
    "        self._dir2 = dir2\n",
    "        \n",
    "    def get(self, filename, to_str):\n",
    "        one = dtc.load(self._dir1, filename)\n",
    "        two = dtc.load(self._dir2, filename)\n",
    "        if (to_str):\n",
    "            one = dlc.to_dict(one)\n",
    "            two = dlc.to_dict(two)\n",
    "        return one, two\n",
    "\n",
    "    def print_dict(self, filename, to_str):\n",
    "        one, two = self.get(filename, to_str)\n",
    "        dtc.pprint(dlc.diff_dict(one, two))\n",
    "    \n",
    "    def _table(self, filename):\n",
    "        one, two = self.get(filename, False)\n",
    "        head, tail = dlc.diff_table(one, two)\n",
    "        display(pd.DataFrame(head))\n",
    "        display(pd.DataFrame(tail))\n",
    "        \n",
    "    def args(self, to_str=True):\n",
    "        self._table('args.pkl')        \n",
    "        \n",
    "    def hyper(self, to_str=True):\n",
    "        self._table('hyper.pkl')\n",
    "    \n",
    "    def get_args(self):\n",
    "        return self.get('args.pkl', to_str=True)\n",
    "    def get_hyper(self):\n",
    "        return self.get('hyper.pkl', to_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v = Visualize('./tb_metrics_dev/2017-10-06 17-56-47 PDT/store', '../data/generated2')\n",
    "# v = VisualizeDir('./tb_metrics/2017-10-08 12-26-45 PDT/store')\n",
    "# v = VisualizeDir('./tb_metrics_dev/2017-10-09 12-45-15 PDT/store')\n",
    "# vd = VisualizeDir('./tb_metrics/2017-10-09 17-43-49 PDT/store')\n",
    "# vd = VisualizeDir('tb_metrics/2017-10-09 16-01-07 PDT/store')\n",
    "# vd2 = VisualizeDir('tb_metrics/2017-09-26 22-40-18 PDT/new_code 2017-10-10 15-10-17 PDT/store')\n",
    "# vd = VisualizeDir('./tb_metrics/2017-10-07 14-33-35 PDT_my_decoder/store')\n",
    "# vd = VisualizeDir('./tb_metrics_view/2017-10-10 19-14-54 PDT good 3_decoder_LSTMs_my_decoder/store')\n",
    "# vd = VisualizeDir('./tb_metrics_view/2017-10-11 17-46-12 PDT 3lstm_3att/store')\n",
    "# vd = VisualizeDir('/zpool_3TB/i2l/tb_metrics/2017-10-12 00-15-53 PDT good 3lstm_attMLP/store')\n",
    "# vd = VisualizeDir('./tb_metrics_view/2017-10-12 19-06-32 PDT 3.1LSTM_noShare_3att/store')\n",
    "vd = VisualizeDir('./tb_metrics_view/2017-10-17 15-41-15 PDT 3.1LSTM_3att_noGather/store_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B': 40,\n",
       " 'CALSTM_STACK': [{'B': 40,\n",
       "   'CTCBlankTokenID': None,\n",
       "   'D': 512,\n",
       "   'H': 3,\n",
       "   'K': 557,\n",
       "   'L': 99,\n",
       "   'MaxSeqLen': 151,\n",
       "   'NullTokenID': 0,\n",
       "   'SpaceTokenID': 556,\n",
       "   'StartTokenID': 556,\n",
       "   'W': 33,\n",
       "   'att_layers': {'activation_fn': <function tensorflow.python.ops.math_ops.tanh>,\n",
       "    'biases_initializer': <tensorflow.python.ops.init_ops.Zeros at 0x7f64f831e110>,\n",
       "    'biases_regularizer': None,\n",
       "    'dropout': None,\n",
       "    'layers_units': [512, 512, 512, 1],\n",
       "    'normalizer_fn': None,\n",
       "    'op_name': 'MLP',\n",
       "    'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "     'tb_activations': 'Activations',\n",
       "     'tb_biases': 'Biases',\n",
       "     'tb_logdir': 'tb_metrics',\n",
       "     'tb_weights': 'Weights'},\n",
       "    'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       "    'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>},\n",
       "   'att_share_weights': True,\n",
       "   'att_weighted_gather': False,\n",
       "   'biases_initializer': <tensorflow.python.ops.init_ops.Zeros at 0x7f64f831e110>,\n",
       "   'biases_regularizer': None,\n",
       "   'build_image_context': 0,\n",
       "   'decoder_lstm': {'B': 40,\n",
       "    'dropout': None,\n",
       "    'dtype': tf.float32,\n",
       "    'forget_bias': 1.0,\n",
       "    'i': 576,\n",
       "    'layers_units': [1000, 1000, 1000],\n",
       "    'op_name': 'LSTMWrapper',\n",
       "    'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "     'tb_activations': 'Activations',\n",
       "     'tb_biases': 'Biases',\n",
       "     'tb_logdir': 'tb_metrics',\n",
       "     'tb_weights': 'Weights'},\n",
       "    'type': 'lstm',\n",
       "    'use_peephole': True,\n",
       "    'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       "    'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>},\n",
       "   'dropout': None,\n",
       "   'dtype': tf.float32,\n",
       "   'dtype_np': numpy.float32,\n",
       "   'image_shape_unframed': [120, 1075, 3],\n",
       "   'int_type': tf.int32,\n",
       "   'int_type_np': numpy.int32,\n",
       "   'logger': <logging.Logger at 0x7f645c73ffd0>,\n",
       "   'm': 64,\n",
       "   'n': 1000,\n",
       "   'rLambda': 5e-05,\n",
       "   'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "    'tb_activations': 'Activations',\n",
       "    'tb_biases': 'Biases',\n",
       "    'tb_logdir': 'tb_metrics',\n",
       "    'tb_weights': 'Weights'},\n",
       "   'use_ctc_loss': False,\n",
       "   'use_peephole': True,\n",
       "   'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       "   'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>}],\n",
       " 'CONVNET': None,\n",
       " 'CTCBlankTokenID': None,\n",
       " 'D': 512,\n",
       " 'DecodingSlack': 20,\n",
       " 'H': 3,\n",
       " 'K': 557,\n",
       " 'L': 99,\n",
       " 'MaxDecodeLen': 171,\n",
       " 'MaxSeqLen': 151,\n",
       " 'MeanSumAlphaEquals1': False,\n",
       " 'NullTokenID': 0,\n",
       " 'SpaceTokenID': 556,\n",
       " 'StartTokenID': 556,\n",
       " 'W': 33,\n",
       " 'adam_alpha': 0.0001,\n",
       " 'assert_whole_batch': False,\n",
       " 'beamsearch_length_penalty': 1.0,\n",
       " 'biases_initializer': <tensorflow.python.ops.init_ops.Zeros at 0x7f64f831e110>,\n",
       " 'biases_regularizer': None,\n",
       " 'build_image_context': 0,\n",
       " 'ctc_beam_width': 10,\n",
       " 'data_reader_B': 80,\n",
       " 'dropout': None,\n",
       " 'dtype': tf.float32,\n",
       " 'dtype_np': numpy.float32,\n",
       " 'embeddings_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       " 'embeddings_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>,\n",
       " 'image_frame_width': 0,\n",
       " 'image_shape': [120, 1075, 3],\n",
       " 'image_shape_unframed': [120, 1075, 3],\n",
       " 'init_model': {'activation_fn': <function tensorflow.python.ops.gen_nn_ops.relu>,\n",
       "  'biases_initializer': <tensorflow.python.ops.init_ops.Zeros at 0x7f64f831e110>,\n",
       "  'biases_regularizer': None,\n",
       "  'dropout': None,\n",
       "  'layers_units': [512],\n",
       "  'normalizer_fn': None,\n",
       "  'op_name': 'MLP',\n",
       "  'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "   'tb_activations': 'Activations',\n",
       "   'tb_biases': 'Biases',\n",
       "   'tb_logdir': 'tb_metrics',\n",
       "   'tb_weights': 'Weights'},\n",
       "  'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       "  'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>},\n",
       " 'init_model_final_layers': {'activation_fn': <function tensorflow.python.ops.math_ops.tanh>,\n",
       "  'biases_initializer': <tensorflow.python.ops.init_ops.Zeros at 0x7f64f831e110>,\n",
       "  'biases_regularizer': None,\n",
       "  'dropout': None,\n",
       "  'normalizer_fn': None,\n",
       "  'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "   'tb_activations': 'Activations',\n",
       "   'tb_biases': 'Biases',\n",
       "   'tb_logdir': 'tb_metrics',\n",
       "   'tb_weights': 'Weights'},\n",
       "  'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       "  'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>},\n",
       " 'input_queue_capacity': 6,\n",
       " 'int_type': tf.int32,\n",
       " 'int_type_np': numpy.int32,\n",
       " 'k': 5,\n",
       " 'logger': <logging.Logger at 0x7f645c73ffd0>,\n",
       " 'm': 64,\n",
       " 'n': 1000,\n",
       " 'no_ctc_merge_repeated': True,\n",
       " 'no_towers': False,\n",
       " 'num_gpus': 2,\n",
       " 'optimizer': <tensorflow.python.training.adam.AdamOptimizer at 0x7f645c73f7d0>,\n",
       " 'output_follow_paper': True,\n",
       " 'output_layers': {'activation_fn': <function tensorflow.python.ops.gen_nn_ops.relu>,\n",
       "  'biases_initializer': <tensorflow.python.ops.init_ops.Zeros at 0x7f64f831e110>,\n",
       "  'biases_regularizer': None,\n",
       "  'dropout': None,\n",
       "  'layers_units': [64, 557],\n",
       "  'normalizer_fn': None,\n",
       "  'op_name': 'yLogits_MLP',\n",
       "  'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "   'tb_activations': 'Activations',\n",
       "   'tb_biases': 'Biases',\n",
       "   'tb_logdir': 'tb_metrics',\n",
       "   'tb_weights': 'Weights'},\n",
       "  'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       "  'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>},\n",
       " 'pLambda': 0.005,\n",
       " 'rLambda': 5e-05,\n",
       " 'seq2seq_beam_width': 10,\n",
       " 'squash_input_seq': True,\n",
       " 'sum_logloss': False,\n",
       " 'swap_memory': False,\n",
       " 'tb': {'logdir_tag': '3.1LSTM_3att_noGather',\n",
       "  'tb_activations': 'Activations',\n",
       "  'tb_biases': 'Biases',\n",
       "  'tb_logdir': 'tb_metrics',\n",
       "  'tb_weights': 'Weights'},\n",
       " 'tf_session_allow_growth': False,\n",
       " 'use_ctc_loss': False,\n",
       " 'use_peephole': True,\n",
       " 'weights_initializer': <function tensorflow.contrib.layers.python.layers.initializers._initializer>,\n",
       " 'weights_regularizer': <function tensorflow.contrib.layers.python.layers.regularizers.l2>}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vd.prune_logs(save_epochs=0, dry_run=False)\n",
    "# vd.prune_snapshots(keep=5, dry_run=False)\n",
    "vd.hyper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134680, 24864)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(vd.max_steps)\n",
    "# display(vd2.max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (object 'predicted_ids' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c7362a95f4db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVisualizeStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m134680\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predicted_ids'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmingle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-78246fd88777>\u001b[0m in \u001b[0;36mstrs\u001b[0;34m(self, graph, key, key2, mingle)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmingle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_visualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmingle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDiffParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78246fd88777>\u001b[0m in \u001b[0;36mstrs\u001b[0;34m(self, graph, step, key, key2, mingle)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmingle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mdf_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mdf_str2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78246fd88777>\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, graph, step, key, key2)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey2\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78246fd88777>\u001b[0m in \u001b[0;36mdf\u001b[0;34m(self, graph, step, key)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-78246fd88777>\u001b[0m in \u001b[0;36mnp\u001b[0;34m(self, graph, step, key)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[1;32m     58\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storedir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%s_%d.h5'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/sumeet/anaconda2/envs/im2latex/lib/python2.7/site-packages/h5py/_hl/group.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (object 'predicted_ids' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "vs = VisualizeStep(vd, 134680)\n",
    "vs.strs('training', 'predicted_ids', 'y', mingle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALSTM_STACK_1.att_layers.layers_units ===&gt; [512, 512]</td>\n",
       "      <td>CALSTM_STACK_1.att_layers.layers_units ===&gt; [99, 99, 99]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output_layers.tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>output_layers.tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>init_model.tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>init_model.tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALSTM_STACK_1.att_share_weights ===&gt; True</td>\n",
       "      <td>CALSTM_STACK_1.att_share_weights ===&gt; False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>init_model_final_layers.tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>init_model_final_layers.tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.layers_units ===&gt; [1000, 1000, 557]</td>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.layers_units ===&gt; [1000, 1000, 1000]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CALSTM_STACK_1.att_layers.tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>CALSTM_STACK_1.att_layers.tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CALSTM_STACK_1.tb.logdir_tag ===&gt; 3lstm_2att</td>\n",
       "      <td>CALSTM_STACK_1.tb.logdir_tag ===&gt; 3.1LSTM_noShare_3att</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  0                                                                1                                                                   \n",
       "0           CALSTM_STACK_1.att_layers.layers_units ===> [512, 512]             CALSTM_STACK_1.att_layers.layers_units ===> [99, 99, 99]\n",
       "1                      output_layers.tb.logdir_tag ===> 3lstm_2att                output_layers.tb.logdir_tag ===> 3.1LSTM_noShare_3att\n",
       "2                         init_model.tb.logdir_tag ===> 3lstm_2att                   init_model.tb.logdir_tag ===> 3.1LSTM_noShare_3att\n",
       "3                       CALSTM_STACK_1.att_share_weights ===> True                          CALSTM_STACK_1.att_share_weights ===> False\n",
       "4                                    tb.logdir_tag ===> 3lstm_2att                              tb.logdir_tag ===> 3.1LSTM_noShare_3att\n",
       "5        CALSTM_STACK_1.decoder_lstm.tb.logdir_tag ===> 3lstm_2att  CALSTM_STACK_1.decoder_lstm.tb.logdir_tag ===> 3.1LSTM_noShare_3att\n",
       "6            init_model_final_layers.tb.logdir_tag ===> 3lstm_2att      init_model_final_layers.tb.logdir_tag ===> 3.1LSTM_noShare_3att\n",
       "7  CALSTM_STACK_1.decoder_lstm.layers_units ===> [1000, 1000, 557]     CALSTM_STACK_1.decoder_lstm.layers_units ===> [1000, 1000, 1000]\n",
       "8          CALSTM_STACK_1.att_layers.tb.logdir_tag ===> 3lstm_2att    CALSTM_STACK_1.att_layers.tb.logdir_tag ===> 3.1LSTM_noShare_3att\n",
       "9                     CALSTM_STACK_1.tb.logdir_tag ===> 3lstm_2att               CALSTM_STACK_1.tb.logdir_tag ===> 3.1LSTM_noShare_3att"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CALSTM_STACK_1.logger ===&gt; undefined</td>\n",
       "      <td>CALSTM_STACK_1.logger ===&gt; &lt;logging.Logger object at 0x7ff0abbb5b90&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>init_model.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>init_model.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CALSTM_STACK_1.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>CALSTM_STACK_1.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALSTM_STACK_1.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0&gt;</td>\n",
       "      <td>CALSTM_STACK_1.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>init_model_final_layers.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>init_model_final_layers.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>embeddings_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>embeddings_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0&gt;</td>\n",
       "      <td>biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>embeddings_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>embeddings_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CALSTM_STACK_1.att_layers.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>CALSTM_STACK_1.att_layers.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CALSTM_STACK_1.att_layers.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>CALSTM_STACK_1.att_layers.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>logger ===&gt; undefined</td>\n",
       "      <td>logger ===&gt; &lt;logging.Logger object at 0x7ff0abbb5b90&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>init_model.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>init_model.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>optimizer ===&gt; &lt;tensorflow.python.training.adam.AdamOptimizer object at 0x7ff0abbb5850&gt;</td>\n",
       "      <td>optimizer ===&gt; &lt;tensorflow.python.training.adam.AdamOptimizer object at 0x7ff0abbb5cd0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CALSTM_STACK_1.att_layers.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0&gt;</td>\n",
       "      <td>CALSTM_STACK_1.att_layers.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>init_model_final_layers.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>init_model_final_layers.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>output_layers.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0&gt;</td>\n",
       "      <td>output_layers.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CALSTM_STACK_1.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>CALSTM_STACK_1.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>output_layers.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>output_layers.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>init_model.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0&gt;</td>\n",
       "      <td>init_model.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>output_layers.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>output_layers.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>init_model_final_layers.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0&gt;</td>\n",
       "      <td>init_model_final_layers.biases_initializer ===&gt; &lt;tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abce1cf8&gt;</td>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.weights_initializer ===&gt; &lt;function _initializer at 0x7ff0abb6f320&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abca0668&gt;</td>\n",
       "      <td>CALSTM_STACK_1.decoder_lstm.weights_regularizer ===&gt; &lt;function l2 at 0x7ff0abb6f230&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                                                                                  1                                                                                                                 \n",
       "0                                                                                CALSTM_STACK_1.logger ===> undefined                                               CALSTM_STACK_1.logger ===> <logging.Logger object at 0x7ff0abbb5b90>\n",
       "1                                       init_model.weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                                      init_model.weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "2                                             CALSTM_STACK_1.weights_regularizer ===> <function l2 at 0x7ff0abca0668>                                            CALSTM_STACK_1.weights_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "3              CALSTM_STACK_1.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0>             CALSTM_STACK_1.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0>\n",
       "4                                    init_model_final_layers.weights_regularizer ===> <function l2 at 0x7ff0abca0668>                                   init_model_final_layers.weights_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "5                                                         embeddings_regularizer ===> <function l2 at 0x7ff0abca0668>                                                        embeddings_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "6                             biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0>                            biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0>\n",
       "7                                               embeddings_initializer ===> <function _initializer at 0x7ff0abce1cf8>                                              embeddings_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "8                        CALSTM_STACK_1.att_layers.weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                       CALSTM_STACK_1.att_layers.weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "9                                  CALSTM_STACK_1.att_layers.weights_regularizer ===> <function l2 at 0x7ff0abca0668>                                 CALSTM_STACK_1.att_layers.weights_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "10                                                                                              logger ===> undefined                                                              logger ===> <logging.Logger object at 0x7ff0abbb5b90>\n",
       "11                                                init_model.weights_regularizer ===> <function l2 at 0x7ff0abca0668>                                                init_model.weights_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "12                            optimizer ===> <tensorflow.python.training.adam.AdamOptimizer object at 0x7ff0abbb5850>                            optimizer ===> <tensorflow.python.training.adam.AdamOptimizer object at 0x7ff0abbb5cd0>\n",
       "13  CALSTM_STACK_1.att_layers.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0>  CALSTM_STACK_1.att_layers.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0>\n",
       "14                         init_model_final_layers.weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                         init_model_final_layers.weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "15              output_layers.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0>              output_layers.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0>\n",
       "16                                                 weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                                                 weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "17                                  CALSTM_STACK_1.weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                                  CALSTM_STACK_1.weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "18                                             output_layers.weights_regularizer ===> <function l2 at 0x7ff0abca0668>                                             output_layers.weights_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "19                 init_model.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0>                 init_model.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0>\n",
       "20                                   output_layers.weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                                   output_layers.weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "21    init_model_final_layers.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb56d0>    init_model_final_layers.biases_initializer ===> <tensorflow.python.ops.init_ops.Zeros object at 0x7ff0abbb59d0>\n",
       "22                     CALSTM_STACK_1.decoder_lstm.weights_initializer ===> <function _initializer at 0x7ff0abce1cf8>                     CALSTM_STACK_1.decoder_lstm.weights_initializer ===> <function _initializer at 0x7ff0abb6f320>\n",
       "23                                                           weights_regularizer ===> <function l2 at 0x7ff0abca0668>                                                           weights_regularizer ===> <function l2 at 0x7ff0abb6f230>\n",
       "24                               CALSTM_STACK_1.decoder_lstm.weights_regularizer ===> <function l2 at 0x7ff0abca0668>                               CALSTM_STACK_1.decoder_lstm.weights_regularizer ===> <function l2 at 0x7ff0abb6f230>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# diff = DiffParams('./tb_metrics/2017-09-26 22-40-18 PDT', './tb_metrics/2017-10-07 14-33-35 PDT_2CALSTMs')\n",
    "# diff = DiffParams('./tb_metrics/2017-10-07 14-33-35 PDT', './tb_metrics/2017-10-08 12-26-45 PDT')\n",
    "# diff = DiffParams('./tb_metrics/2017-09-26 22-40-18 PDT', './tb_metrics/2017-10-08 12-26-45 PDT')\n",
    "# diff = DiffParams('./tb_metrics/2017-09-26 22-40-18 PDT/w=1', './tb_metrics/2017-10-08 12-26-45 PDT')\n",
    "# diff = DiffParams('./tb_metrics/2017-10-09 16-01-07 PDT_good', './tb_metrics/2017-10-09 17-43-49 PDT')\n",
    "# diff = DiffParams('./tb_metrics/2017-09-26 22-40-18 PDT', './tb_metrics/2017-10-09 16-01-07 PDT_good')\n",
    "diff = DiffParams('./tb_metrics_view/2017-10-11 17-46-12 PDT 3lstm_2att', './tb_metrics_view/2017-10-12 19-06-32 PDT 3.1LSTM_noShare_3att')\n",
    "diff.hyper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diff.get_hyper()[1]['CALSTM_STACK'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
